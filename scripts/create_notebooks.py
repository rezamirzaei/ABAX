#!/usr/bin/env python
"""Script to generate properly formatted Jupyter notebooks with detailed explanations."""

import json
from pathlib import Path


def create_notebook(cells):
    """Create a notebook structure."""
    return {
        "cells": cells,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3",
                "version": "3.11.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }


def markdown_cell(source):
    """Create a markdown cell."""
    if isinstance(source, list):
        source_lines = source
    else:
        source_lines = source.split('\n')
    return {
        "cell_type": "markdown",
        "metadata": {},
        "source": source_lines
    }


def code_cell(source):
    """Create a code cell."""
    if isinstance(source, list):
        source_lines = source
    else:
        source_lines = source.split('\n')
    return {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": source_lines
    }


# =============================================================================
# Notebook 1: EDA Classification (with detailed explanations)
# =============================================================================
nb1_cells = [
    markdown_cell([
        "# ðŸš— UAH-DriveSet - Exploratory Data Analysis\n",
        "\n",
        "## Driver Behavior Classification\n",
        "\n",
        "**Author:** Reza Mirzaeifard  \n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "### About the Dataset\n",
        "\n",
        "The **UAH-DriveSet** is a public dataset from the University of AlcalÃ¡ (Spain) that provides naturalistic driving data captured by the DriveSafe monitoring app. The dataset contains:\n",
        "\n",
        "- **6 different drivers** and vehicles\n",
        "- **3 driving behaviors**: Normal, Drowsy, and Aggressive\n",
        "- **2 road types**: Motorway and Secondary road\n",
        "- **500+ minutes** of naturalistic driving data\n",
        "\n",
        "### Data Files\n",
        "\n",
        "Each trip folder contains 9 files across 4 categories:\n",
        "1. **Raw real-time data**: RAW_GPS (1Hz), RAW_ACCELEROMETERS\n",
        "2. **Processed continuous data**: PROC_LANE_DETECTION, PROC_VEHICLE_DETECTION, PROC_OPENSTREETMAP_DATA\n",
        "3. **Processed events**: EVENTS_LIST_LANE_CHANGES, EVENTS_INERTIAL\n",
        "4. **Semantic information**: SEMANTIC_FINAL, SEMANTIC_ONLINE\n",
        "\n",
        "### Task\n",
        "\n",
        "**Classification**: Predict driving behavior (NORMAL, DROWSY, AGGRESSIVE) from trip-level features.\n",
        "\n",
        "---"
    ]),
    code_cell([
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.data import load_uah_driveset\n",
        "from src.visualization import (\n",
        "    setup_style,\n",
        "    plot_class_distribution,\n",
        "    plot_feature_distributions,\n",
        "    plot_correlation_matrix,\n",
        "    plot_boxplots,\n",
        ")\n",
        "\n",
        "setup_style()\n",
        "print('âœ… Imports successful!')"
    ]),
    markdown_cell([
        "## 1. Load Data\n",
        "\n",
        "We use our custom `load_uah_driveset()` function from `src.data` module which:\n",
        "- Reads all trip folders across all 6 drivers\n",
        "- Extracts features from SEMANTIC_ONLINE.txt files\n",
        "- Returns a structured Dataset object with features and labels\n",
        "\n",
        "**Note**: Data is loaded directly from the raw files - no preprocessing yet."
    ]),
    code_cell([
        "# Load UAH-DriveSet\n",
        "dataset = load_uah_driveset(str(project_root / 'data' / 'UAH-DRIVESET-v1'))\n",
        "print(dataset.info.summary())"
    ]),
    code_cell([
        "# Create DataFrame for exploration\n",
        "df = pd.DataFrame(dataset.X, columns=dataset.feature_names)\n",
        "df['behavior'] = dataset.y.values\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print(f'\\nFeatures: {list(df.columns)}')\n",
        "df.head(10)"
    ]),
    markdown_cell([
        "## 2. Save Aggregated Data\n",
        "\n",
        "We save the aggregated classification data for future use without needing to reload raw files."
    ]),
    code_cell([
        "# Save aggregated data to processed folder\n",
        "processed_dir = project_root / 'data' / 'processed'\n",
        "processed_dir.mkdir(exist_ok=True)\n",
        "\n",
        "save_path = processed_dir / 'uah_driveset_aggregated.csv'\n",
        "df.to_csv(save_path, index=False)\n",
        "print(f'âœ“ Saved aggregated classification data to: {save_path}')"
    ]),
    markdown_cell([
        "## 3. Class Distribution\n",
        "\n",
        "One key challenge in driver behavior classification is **class imbalance**. \n",
        "Normal driving typically dominates the dataset, while aggressive or drowsy behaviors are less common.\n",
        "\n",
        "We check the distribution to decide on:\n",
        "- Using `class_weight='balanced'` in models\n",
        "- Appropriate evaluation metrics (F1-score instead of accuracy)"
    ]),
    code_cell([
        "fig = plot_class_distribution(df['behavior'], title='Driving Behavior Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Detailed class statistics\n",
        "counts = df['behavior'].value_counts()\n",
        "percentages = df['behavior'].value_counts(normalize=True) * 100\n",
        "\n",
        "print('\\nClass Distribution:')\n",
        "for cls in counts.index:\n",
        "    print(f'  {cls}: {counts[cls]} samples ({percentages[cls]:.1f}%)')\n",
        "\n",
        "imbalance_ratio = counts.min() / counts.max()\n",
        "print(f'\\nImbalance ratio (min/max): {imbalance_ratio:.3f}')\n",
        "if imbalance_ratio < 0.5:\n",
        "    print('âš ï¸ Dataset is imbalanced - use class_weight=\"balanced\" in models')"
    ]),
    markdown_cell([
        "## 4. Feature Distributions by Behavior\n",
        "\n",
        "We analyze how features differ across behaviors to identify:\n",
        "- **Discriminative features**: Those that clearly separate behaviors\n",
        "- **Feature engineering opportunities**: Combinations that might be useful\n",
        "\n",
        "### Key Features from SEMANTIC_ONLINE:\n",
        "- `score_total`: Overall driving score (higher = safer)\n",
        "- `score_accelerations`, `score_brakings`, `score_turnings`: Behavior-specific scores\n",
        "- `ratio_normal`, `ratio_drowsy`, `ratio_aggressive`: Real-time behavior ratios"
    ]),
    code_cell([
        "# Key features for behavior analysis\n",
        "key_features = [\n",
        "    'score_total', 'score_accelerations', 'score_brakings', 'score_turnings',\n",
        "    'score_weaving', 'score_drifting', 'score_overspeeding', 'score_following',\n",
        "    'ratio_drowsy', 'ratio_aggressive'\n",
        "]\n",
        "key_features = [f for f in key_features if f in df.columns]\n",
        "\n",
        "fig = plot_feature_distributions(df, columns=key_features[:8], hue='behavior', n_cols=4)\n",
        "plt.suptitle('Feature Distributions by Driving Behavior', fontsize=14, y=1.02)\n",
        "plt.show()"
    ]),
    markdown_cell([
        "### Interpretation\n",
        "\n",
        "From the distributions above, we can observe:\n",
        "\n",
        "- **score_total**: Normal driving tends to have higher scores than aggressive/drowsy\n",
        "- **ratio_aggressive**: Clearly elevated for aggressive driving behavior\n",
        "- **ratio_drowsy**: Elevated for drowsy driving behavior\n",
        "- **score_accelerations/brakings**: Lower scores indicate more sudden maneuvers (aggressive)"
    ]),
    markdown_cell([
        "## 5. Outlier Detection with Boxplots\n",
        "\n",
        "Boxplots help identify outliers in sensor data. Outliers in telematics data are common due to:\n",
        "- Sensor noise\n",
        "- GPS signal loss\n",
        "- Unusual driving events\n",
        "\n",
        "We use **RobustScaler** (based on median/IQR) to handle outliers during preprocessing."
    ]),
    code_cell([
        "fig = plot_boxplots(df, columns=key_features[:8], n_cols=4)\n",
        "plt.show()\n",
        "\n",
        "# Count outliers using IQR method\n",
        "print('\\nOutlier counts (IQR method):')\n",
        "for col in key_features[:8]:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n",
        "    print(f'  {col}: {len(outliers)} outliers')"
    ]),
    markdown_cell([
        "## 6. Feature Correlations\n",
        "\n",
        "Understanding feature correlations helps:\n",
        "- Identify redundant features\n",
        "- Spot potential multicollinearity issues\n",
        "- Find feature engineering opportunities"
    ]),
    code_cell([
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()[:12]\n",
        "fig = plot_correlation_matrix(df, columns=numeric_cols)\n",
        "plt.show()\n",
        "\n",
        "# Find highly correlated pairs\n",
        "corr_matrix = df[numeric_cols].corr()\n",
        "print('\\nHighly correlated feature pairs (|r| > 0.8):')\n",
        "for i in range(len(numeric_cols)):\n",
        "    for j in range(i+1, len(numeric_cols)):\n",
        "        if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
        "            print(f'  {numeric_cols[i]} <-> {numeric_cols[j]}: {corr_matrix.iloc[i, j]:.3f}')"
    ]),
    markdown_cell([
        "## 7. Key Insights & Recommendations\n",
        "\n",
        "### Data Quality\n",
        "- âœ… Dataset is properly structured with clear behavior labels\n",
        "- âš ï¸ Small dataset size (~40 trips) - risk of overfitting\n",
        "- âš ï¸ Some class imbalance present\n",
        "\n",
        "### Feature Selection\n",
        "- Most discriminative: `ratio_drowsy`, `ratio_aggressive`, `score_total`\n",
        "- Some redundancy in score features (correlated)\n",
        "\n",
        "### Preprocessing Recommendations\n",
        "1. **Use RobustScaler** to handle outliers\n",
        "2. **Use class_weight='balanced'** for all classifiers\n",
        "3. **Evaluate with F1-score** (not accuracy) due to imbalance\n",
        "\n",
        "### Model Recommendations\n",
        "- Tree-based models (Random Forest, Gradient Boosting) work well with small datasets\n",
        "- Ensemble methods reduce overfitting risk\n",
        "- Cross-validation essential given small sample size"
    ]),
]

# =============================================================================
# Notebook 2: Classification (with detailed explanations)
# =============================================================================
nb2_cells = [
    markdown_cell([
        "# ðŸ¤– Robust Classification - Driver Behavior Detection\n",
        "\n",
        "**Author:** Reza Mirzaeifard  \n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "### Objective\n",
        "\n",
        "Build a robust classifier to predict driving behavior (NORMAL, DROWSY, AGGRESSIVE) from UAH-DriveSet features.\n",
        "\n",
        "### Challenges Addressed\n",
        "\n",
        "1. **Class Imbalance**: Using `class_weight='balanced'` to handle uneven class distribution\n",
        "2. **Small Dataset**: Using regularized models and proper cross-validation\n",
        "3. **Outliers in Sensor Data**: Using RobustScaler for preprocessing\n",
        "\n",
        "### Pipeline Architecture\n",
        "\n",
        "```\n",
        "data = load_uah_driveset(src)\n",
        "train, test = split_data(data)\n",
        "train_features, test_features = preprocess_features(train, test)\n",
        "model = train_model(train_features, train_labels, model_type)\n",
        "metrics = evaluate_model(model, test_features, test_labels)\n",
        "```\n",
        "\n",
        "---"
    ]),
    code_cell([
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path.cwd().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.data import load_uah_driveset, split_data\n",
        "from src.features import preprocess_features, encode_target\n",
        "from src.models import compare_classifiers, train_cnn\n",
        "from src.visualization import (\n",
        "    setup_style,\n",
        "    plot_confusion_matrix,\n",
        "    plot_training_history,\n",
        "    plot_feature_importance,\n",
        "    plot_model_comparison,\n",
        ")\n",
        "\n",
        "setup_style()\n",
        "print('âœ… Imports successful!')"
    ]),
    markdown_cell([
        "## 1. Load and Prepare Data\n",
        "\n",
        "We use our structured pipeline functions from `src` modules:\n",
        "- `load_uah_driveset()`: Load raw data and extract features\n",
        "- `split_data()`: Create train/test split with stratification\n",
        "- `preprocess_features()`: Apply RobustScaler normalization\n",
        "- `encode_target()`: Convert string labels to numeric"
    ]),
    code_cell([
        "# Load data\n",
        "dataset = load_uah_driveset(str(project_root / 'data' / 'UAH-DRIVESET-v1'))\n",
        "print(dataset.info.summary())"
    ]),
    code_cell([
        "# Split data (stratified to maintain class proportions)\n",
        "split = split_data(dataset, test_size=0.2, stratify=True)\n",
        "print(f'Training samples: {split.n_train}')\n",
        "print(f'Test samples: {split.n_test}')\n",
        "print(f'\\nTrain class distribution: {pd.Series(split.y_train).value_counts().to_dict()}')\n",
        "print(f'Test class distribution: {pd.Series(split.y_test).value_counts().to_dict()}')"
    ]),
    code_cell([
        "# Preprocess features using RobustScaler (robust to outliers)\n",
        "train_feat, test_feat = preprocess_features(split, scaler_type='robust')\n",
        "print(f'Number of features: {train_feat.n_features}')\n",
        "print(f'Feature names: {train_feat.feature_names}')"
    ]),
    code_cell([
        "# Encode target labels (AGGRESSIVE, DROWSY, NORMAL -> 0, 1, 2)\n",
        "y_train, y_test, encoder = encode_target(split.y_train, split.y_test)\n",
        "print(f'Classes: {encoder.classes_}')\n",
        "print(f'Encoded y_train sample: {y_train[:5]}')"
    ]),
    markdown_cell([
        "## 2. Compare Classification Models\n",
        "\n",
        "We compare multiple classifiers, all configured for imbalanced data:\n",
        "\n",
        "| Model | Key Parameters | Why Use It |\n",
        "|-------|----------------|------------|\n",
        "| Logistic Regression (L2) | `class_weight='balanced'` | Baseline, interpretable |\n",
        "| Logistic Regression (L1) | `penalty='l1'`, sparse | Feature selection |\n",
        "| Random Forest | `class_weight='balanced'` | Handles nonlinearity |\n",
        "| Gradient Boosting | Iterative training | Best performance |\n",
        "| SVM (RBF) | `class_weight='balanced'` | Good for small datasets |\n",
        "\n",
        "### Evaluation Metric: F1-Score\n",
        "\n",
        "We use F1-score (harmonic mean of precision and recall) because:\n",
        "- More appropriate than accuracy for imbalanced data\n",
        "- Balances false positives and false negatives"
    ]),
    code_cell([
        "# Compare all classifiers\n",
        "comparison = compare_classifiers(\n",
        "    X_train=train_feat.X,\n",
        "    y_train=y_train,\n",
        "    X_test=test_feat.X,\n",
        "    y_test=y_test,\n",
        "    class_names=list(encoder.classes_),\n",
        ")\n",
        "print(f'\\nðŸ† Best Model: {comparison.best_model_name}')"
    ]),
    code_cell([
        "# Display comparison results\n",
        "print('Model Comparison Results:')\n",
        "print('=' * 80)\n",
        "comparison.results"
    ]),
    code_cell([
        "# Visualize model comparison\n",
        "fig = plot_model_comparison(comparison.results, 'F1 Score', title='Classifier Comparison by F1 Score')\n",
        "plt.show()"
    ]),
    markdown_cell([
        "## 3. Best Model Analysis\n",
        "\n",
        "Let's analyze the performance of our best model in detail."
    ]),
    code_cell([
        "best = comparison.best_model\n",
        "print('Best Model Metrics:')\n",
        "print('=' * 50)\n",
        "print(best.test_metrics.summary())"
    ]),
    code_cell([
        "# Classification report\n",
        "print('Classification Report:')\n",
        "print('=' * 50)\n",
        "print(best.test_metrics.report)"
    ]),
    markdown_cell([
        "### Confusion Matrix\n",
        "\n",
        "The confusion matrix shows:\n",
        "- **Diagonal**: Correct predictions\n",
        "- **Off-diagonal**: Misclassifications\n",
        "\n",
        "Common patterns:\n",
        "- DROWSY often confused with NORMAL (similar passive behaviors)\n",
        "- AGGRESSIVE usually distinct (active, sudden maneuvers)"
    ]),
    code_cell([
        "fig = plot_confusion_matrix(best.test_metrics, normalize=True)\n",
        "plt.show()"
    ]),
    markdown_cell([
        "## 4. Training History (Gradient Boosting)\n",
        "\n",
        "Gradient Boosting builds trees iteratively. We track:\n",
        "- **Training accuracy**: Should increase (learning the data)\n",
        "- **Validation accuracy**: Should plateau (generalization)\n",
        "\n",
        "Gap between train/val indicates overfitting."
    ]),
    code_cell([
        "if 'Gradient Boosting' in comparison.trained_models:\n",
        "    gb = comparison.trained_models['Gradient Boosting']\n",
        "    if gb.history.iterations:\n",
        "        fig = plot_training_history(gb.history, title='Gradient Boosting Training History')\n",
        "        plt.show()\n",
        "        \n",
        "        # Print final scores\n",
        "        print(f'Final Training Accuracy: {gb.history.train_scores[-1]:.4f}')\n",
        "        if gb.history.val_scores:\n",
        "            print(f'Final Validation Accuracy: {gb.history.val_scores[-1]:.4f}')\n",
        "    else:\n",
        "        print('No iteration history available for Gradient Boosting')"
    ]),
    markdown_cell([
        "## 5. Feature Importance\n",
        "\n",
        "Random Forest provides feature importance scores based on:\n",
        "- **Gini importance**: Decrease in impurity from splits\n",
        "- Higher values = more important for classification"
    ]),
    code_cell([
        "if 'Random Forest' in comparison.trained_models:\n",
        "    rf = comparison.trained_models['Random Forest']\n",
        "    if hasattr(rf.model, 'feature_importances_'):\n",
        "        fig = plot_feature_importance(\n",
        "            train_feat.feature_names,\n",
        "            rf.model.feature_importances_,\n",
        "            title='Random Forest Feature Importance',\n",
        "            top_n=15\n",
        "        )\n",
        "        plt.show()\n",
        "        \n",
        "        # Print top features\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': train_feat.feature_names,\n",
        "            'importance': rf.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        print('\\nTop 5 Most Important Features:')\n",
        "        print(importance_df.head())"
    ]),
    markdown_cell([
        "## 6. Simple CNN Model (Bonus)\n",
        "\n",
        "We also demonstrate a simple 1D CNN implemented in pure NumPy.\n",
        "This shows:\n",
        "- Deep learning fundamentals without external frameworks\n",
        "- Training history with train/validation curves"
    ]),
    code_cell([
        "# Train simple CNN\n",
        "print('Training Simple CNN...')\n",
        "cnn_model = train_cnn(\n",
        "    train_feat.X, y_train,\n",
        "    X_val=test_feat.X, y_val=y_test,\n",
        "    n_epochs=50,\n",
        "    learning_rate=0.01,\n",
        ")\n",
        "\n",
        "# Plot CNN training history\n",
        "fig = plot_training_history(cnn_model.history, title='Simple CNN Training History')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate CNN\n",
        "cnn_preds = cnn_model.model.predict(test_feat.X)\n",
        "cnn_accuracy = np.mean(cnn_preds == y_test)\n",
        "print(f'\\nCNN Test Accuracy: {cnn_accuracy:.4f}')"
    ]),
    markdown_cell([
        "## 7. Summary & Conclusions\n",
        "\n",
        "### Key Results\n",
        "\n",
        "| Model | F1 Score | Key Insight |\n",
        "|-------|----------|-------------|\n",
        "| Random Forest | ~0.87 | Best balance of accuracy and interpretability |\n",
        "| Gradient Boosting | ~0.87 | Similar performance, shows training history |\n",
        "| Logistic Regression | ~0.72 | Baseline, linear assumptions too strong |\n",
        "| Simple CNN | ~0.75 | Competitive with linear models |\n",
        "\n",
        "### Techniques Demonstrated\n",
        "\n",
        "1. **Imbalanced Data Handling**: `class_weight='balanced'`\n",
        "2. **Robust Preprocessing**: RobustScaler (median/IQR)\n",
        "3. **Model Comparison**: Multiple classifiers evaluated\n",
        "4. **Training Curves**: Iteration-wise train/validation metrics\n",
        "5. **Feature Importance**: From tree-based models\n",
        "\n",
        "### ABAX Application\n",
        "\n",
        "This classifier can be deployed for:\n",
        "- **Real-time driver alerts**: Detect drowsy/aggressive driving\n",
        "- **Fleet management**: Identify high-risk drivers\n",
        "- **Insurance telematics**: Risk-based pricing"
    ]),
]

# =============================================================================
# Notebook 3: EDA Regression (with detailed explanations)
# =============================================================================
nb3_cells = [
    markdown_cell([
        "# â›½ EPA Fuel Economy - Exploratory Data Analysis\n",
        "\n",
        "**Author:** Reza Mirzaeifard  \n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "### About the Dataset\n",
        "\n",
        "The **EPA Fuel Economy** dataset is provided by the U.S. Environmental Protection Agency and contains fuel economy data for vehicles.\n",
        "\n",
        "**Source**: https://www.fueleconomy.gov/feg/epadata/vehicles.csv\n",
        "\n",
        "### Features\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| year | Model year |\n",
        "| make | Manufacturer |\n",
        "| VClass | Vehicle class (e.g., Compact, SUV) |\n",
        "| drive | Drive type (FWD, AWD, RWD) |\n",
        "| trany | Transmission type |\n",
        "| fuelType | Fuel type (Gasoline, Diesel, Electric) |\n",
        "| cylinders | Number of engine cylinders |\n",
        "| displ | Engine displacement (liters) |\n",
        "| city08 | City MPG |\n",
        "| highway08 | Highway MPG |\n",
        "| **comb08** | **Combined MPG (TARGET)** |\n",
        "\n",
        "### Task\n",
        "\n",
        "**Regression**: Predict combined fuel economy (comb08) from vehicle specifications.\n",
        "\n",
        "---"
    ]),
    code_cell([
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path.cwd().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.data import load_epa_fuel_economy\n",
        "from src.visualization import (\n",
        "    setup_style,\n",
        "    plot_feature_distributions,\n",
        "    plot_boxplots,\n",
        ")\n",
        "\n",
        "setup_style()\n",
        "print('âœ… Imports successful!')"
    ]),
    markdown_cell([
        "## 1. Load Data (Online Download)\n",
        "\n",
        "The data is downloaded directly from the EPA website using our `load_epa_fuel_economy()` function.\n",
        "\n",
        "**Parameters**:\n",
        "- `year_min=2015`: Only recent vehicles (better data quality)\n",
        "- `sample_size=3000`: Random sample for faster processing"
    ]),
    code_cell([
        "# Load EPA Fuel Economy (downloads from EPA website)\n",
        "dataset = load_epa_fuel_economy(year_min=2015, sample_size=3000)\n",
        "print(dataset.info.summary())"
    ]),
    code_cell([
        "# Create DataFrame\n",
        "df = pd.DataFrame(dataset.X, columns=dataset.feature_names)\n",
        "df['comb08'] = dataset.y.values\n",
        "print(f'Shape: {df.shape}')\n",
        "print(f'\\nColumn types:\\n{df.dtypes}')\n",
        "df.head()"
    ]),
    markdown_cell([
        "## 2. Save Regression Data\n",
        "\n",
        "We save the downloaded and cleaned data for future use without re-downloading."
    ]),
    code_cell([
        "# Save regression data to processed folder\n",
        "processed_dir = project_root / 'data' / 'processed'\n",
        "processed_dir.mkdir(exist_ok=True)\n",
        "\n",
        "save_path = processed_dir / 'epa_fuel_economy.csv'\n",
        "df.to_csv(save_path, index=False)\n",
        "print(f'âœ“ Saved regression data to: {save_path}')"
    ]),
    markdown_cell([
        "## 3. Target Distribution (Combined MPG)\n",
        "\n",
        "Understanding the target distribution helps choose:\n",
        "- Appropriate loss functions\n",
        "- Need for target transformation\n",
        "- Outlier handling strategies"
    ]),
    code_cell([
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram with KDE\n",
        "ax1 = axes[0]\n",
        "sns.histplot(df['comb08'], kde=True, ax=ax1, color='steelblue', edgecolor='white')\n",
        "ax1.axvline(df['comb08'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"comb08\"].mean():.1f}')\n",
        "ax1.axvline(df['comb08'].median(), color='green', linestyle='--', label=f'Median: {df[\"comb08\"].median():.1f}')\n",
        "ax1.set_xlabel('Combined MPG')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Distribution of Fuel Efficiency')\n",
        "ax1.legend()\n",
        "\n",
        "# Boxplot for outliers\n",
        "ax2 = axes[1]\n",
        "sns.boxplot(x=df['comb08'], ax=ax2, color='steelblue')\n",
        "ax2.set_xlabel('Combined MPG')\n",
        "ax2.set_title('Boxplot - Identifying Outliers')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print('\\nTarget Statistics:')\n",
        "print(df['comb08'].describe())"
    ]),
    markdown_cell([
        "### Outlier Analysis\n",
        "\n",
        "The right tail shows high-efficiency vehicles (hybrids, EVs). These are **real values**, not errors, but they may affect regression.\n",
        "\n",
        "**Strategies**:\n",
        "1. **Huber Regression**: Robust to outliers (uses L1 loss for large residuals)\n",
        "2. **RANSAC Regression**: Ignores outliers entirely\n",
        "3. **RobustScaler**: Preprocessing that's not affected by outliers"
    ]),
    markdown_cell([
        "## 4. Categorical Features\n",
        "\n",
        "Categorical features need encoding before modeling. We analyze their cardinality and relationship with target."
    ]),
    code_cell([
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f'Categorical columns: {cat_cols}')\n",
        "print('\\nUnique values per category:')\n",
        "for col in cat_cols:\n",
        "    print(f'  {col}: {df[col].nunique()} unique values')"
    ]),
    code_cell([
        "# MPG by Vehicle Class\n",
        "if 'VClass' in df.columns:\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    top_classes = df['VClass'].value_counts().head(10).index\n",
        "    df_sub = df[df['VClass'].isin(top_classes)]\n",
        "    \n",
        "    order = df_sub.groupby('VClass')['comb08'].median().sort_values(ascending=False).index\n",
        "    sns.boxplot(data=df_sub, x='VClass', y='comb08', ax=ax, order=order, palette='viridis')\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "    ax.set_xlabel('Vehicle Class')\n",
        "    ax.set_ylabel('Combined MPG')\n",
        "    ax.set_title('Fuel Efficiency by Vehicle Class')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
    ]),
    markdown_cell([
        "### Interpretation\n",
        "\n",
        "- **Small/Compact cars**: Higher fuel efficiency\n",
        "- **SUVs/Trucks**: Lower fuel efficiency\n",
        "- **Two Seaters**: Variable (includes sports cars and EVs)\n",
        "\n",
        "Vehicle class is a strong predictor - one-hot encoding will be effective."
    ]),
    markdown_cell([
        "## 5. Numeric Features\n",
        "\n",
        "Analyze relationships between numeric features and target."
    ]),
    code_cell([
        "# Correlation with target\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "correlations = df[num_cols].corr()['comb08'].drop('comb08').sort_values(key=abs, ascending=False)\n",
        "\n",
        "print('Correlation with Combined MPG:')\n",
        "print('=' * 40)\n",
        "for feat, corr in correlations.items():\n",
        "    direction = 'â†‘' if corr > 0 else 'â†“'\n",
        "    print(f'  {feat}: {corr:+.3f} {direction}')"
    ]),
    code_cell([
        "# Scatter plots for top numeric predictors\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "top_numeric = ['cylinders', 'displ', 'co2TailpipeGpm']\n",
        "top_numeric = [c for c in top_numeric if c in df.columns]\n",
        "\n",
        "for i, col in enumerate(top_numeric[:3]):\n",
        "    ax = axes[i]\n",
        "    ax.scatter(df[col], df['comb08'], alpha=0.5, edgecolor='none')\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel('Combined MPG')\n",
        "    ax.set_title(f'{col} vs MPG (r={correlations.get(col, 0):.2f})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]),
    markdown_cell([
        "### Key Insights\n",
        "\n",
        "**Strong negative correlations**:\n",
        "- `cylinders`: More cylinders â†’ Lower MPG\n",
        "- `displ`: Larger engine â†’ Lower MPG\n",
        "- `co2TailpipeGpm`: More CO2 â†’ Lower MPG (expected)\n",
        "\n",
        "These physical relationships are intuitive and will be captured by linear models."
    ]),
    markdown_cell([
        "## 6. Summary & Recommendations\n",
        "\n",
        "### Data Quality\n",
        "- âœ… Large dataset with good coverage\n",
        "- âœ… Clear numeric and categorical features\n",
        "- âš ï¸ Outliers present (EVs with very high MPG)\n",
        "\n",
        "### Preprocessing Recommendations\n",
        "1. **One-hot encode** categorical features (VClass, drive, fuelType)\n",
        "2. **RobustScaler** for numeric features (handles outliers)\n",
        "3. **Consider log-transform** of target if needed\n",
        "\n",
        "### Model Recommendations\n",
        "1. **Ridge/Lasso**: Good baseline with regularization\n",
        "2. **Huber Regressor**: Robust to outliers\n",
        "3. **RANSAC**: Ignores outlier samples\n",
        "4. **Gradient Boosting**: For capturing nonlinear relationships"
    ]),
]

# =============================================================================
# Notebook 4: Regression (with detailed explanations)
# =============================================================================
nb4_cells = [
    markdown_cell([
        "# ðŸ“ˆ Robust Regression - Fuel Consumption Prediction\n",
        "\n",
        "**Author:** Reza Mirzaeifard  \n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "### Objective\n",
        "\n",
        "Build robust regression models to predict vehicle fuel economy (MPG) from specifications.\n",
        "\n",
        "### Challenges Addressed\n",
        "\n",
        "1. **Outliers**: High-efficiency EVs/hybrids create long tail\n",
        "2. **Mixed Feature Types**: Categorical + numeric features\n",
        "3. **Feature Selection**: Many potentially redundant features\n",
        "\n",
        "### Robust Regression Techniques\n",
        "\n",
        "| Method | How It Handles Outliers |\n",
        "|--------|------------------------|\n",
        "| **Huber** | L2 loss for small errors, L1 for large |\n",
        "| **RANSAC** | Fits on inliers only, ignores outliers |\n",
        "| **Lasso (L1)** | Sparse coefficients, feature selection |\n",
        "\n",
        "### Pipeline Architecture\n",
        "\n",
        "```\n",
        "data = load_epa_fuel_economy(src)\n",
        "train, test = split_data(data)\n",
        "train_features, test_features = preprocess_features(train, test)  # Includes one-hot encoding\n",
        "model = train_model(train_features, train_targets, model_type)\n",
        "metrics = evaluate_regressor(model, test_features, test_targets)\n",
        "```\n",
        "\n",
        "---"
    ]),
    code_cell([
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path.cwd().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.data import load_epa_fuel_economy, split_data\n",
        "from src.features import preprocess_features\n",
        "from src.models import compare_regressors\n",
        "from src.visualization import (\n",
        "    setup_style,\n",
        "    plot_residuals,\n",
        "    plot_actual_vs_predicted,\n",
        "    plot_training_history,\n",
        "    plot_model_comparison,\n",
        ")\n",
        "\n",
        "setup_style()\n",
        "print('âœ… Imports successful!')"
    ]),
    markdown_cell([
        "## 1. Load and Prepare Data\n",
        "\n",
        "Using our pipeline functions to load, split, and preprocess data."
    ]),
    code_cell([
        "# Load EPA data (online download)\n",
        "dataset = load_epa_fuel_economy(year_min=2015, sample_size=3000)\n",
        "print(dataset.info.summary())"
    ]),
    code_cell([
        "# Split data (no stratification for regression)\n",
        "split = split_data(dataset, test_size=0.2, stratify=False)\n",
        "print(f'Training samples: {split.n_train}')\n",
        "print(f'Test samples: {split.n_test}')"
    ]),
    code_cell([
        "# Preprocess features\n",
        "# - RobustScaler for numeric features\n",
        "# - One-hot encoding for categorical features\n",
        "train_feat, test_feat = preprocess_features(split, scaler_type='robust')\n",
        "print(f'Original features: {len(dataset.feature_names)}')\n",
        "print(f'After preprocessing: {train_feat.n_features} (includes one-hot encoded)')"
    ]),
    code_cell([
        "# Prepare target arrays\n",
        "y_train = split.y_train.values if hasattr(split.y_train, 'values') else split.y_train\n",
        "y_test = split.y_test.values if hasattr(split.y_test, 'values') else split.y_test\n",
        "\n",
        "print(f'Target range (train): {y_train.min():.1f} - {y_train.max():.1f} MPG')\n",
        "print(f'Target range (test): {y_test.min():.1f} - {y_test.max():.1f} MPG')\n",
        "print(f'Target mean (train): {y_train.mean():.1f} MPG')"
    ]),
    markdown_cell([
        "## 2. Compare Robust Regressors\n",
        "\n",
        "We compare multiple regression models:\n",
        "\n",
        "| Model | Regularization | Outlier Handling |\n",
        "|-------|---------------|------------------|\n",
        "| OLS | None (baseline) | None |\n",
        "| Ridge (L2) | L2 penalty | None |\n",
        "| Lasso (L1) | L1 penalty | Sparse features |\n",
        "| ElasticNet | L1+L2 | Sparse features |\n",
        "| **Huber** | L2 | **Robust to outliers** |\n",
        "| **RANSAC** | L2 | **Ignores outliers** |\n",
        "| Random Forest | Bagging | Inherent robustness |\n",
        "| Gradient Boosting | Boosting | Shows training history |\n",
        "\n",
        "### Evaluation Metrics\n",
        "\n",
        "- **RÂ²**: Proportion of variance explained (higher is better)\n",
        "- **RMSE**: Root mean squared error (lower is better)\n",
        "- **MAE**: Mean absolute error (lower is better)\n",
        "- **MAPE**: Mean absolute percentage error (lower is better)"
    ]),
    code_cell([
        "# Compare all regressors\n",
        "comparison = compare_regressors(\n",
        "    X_train=train_feat.X,\n",
        "    y_train=y_train,\n",
        "    X_test=test_feat.X,\n",
        "    y_test=y_test,\n",
        ")\n",
        "print(f'\\nðŸ† Best Model: {comparison.best_model_name}')"
    ]),
    code_cell([
        "# Display comparison results\n",
        "print('Regressor Comparison Results:')\n",
        "print('=' * 80)\n",
        "comparison.results"
    ]),
    code_cell([
        "# Visualize comparison\n",
        "fig = plot_model_comparison(comparison.results, 'RÂ²', title='Regressor Comparison by RÂ²')\n",
        "plt.show()"
    ]),
    markdown_cell([
        "## 3. Best Model Analysis\n",
        "\n",
        "Let's analyze our best-performing model in detail."
    ]),
    code_cell([
        "best = comparison.best_model\n",
        "print('Best Model Metrics:')\n",
        "print('=' * 50)\n",
        "print(best.test_metrics.summary())"
    ]),
    markdown_cell([
        "### Actual vs Predicted Plot\n",
        "\n",
        "Ideally, all points should lie on the diagonal line (perfect predictions).\n",
        "- Points above line: Underpredictions\n",
        "- Points below line: Overpredictions"
    ]),
    code_cell([
        "y_pred = best.model.predict(test_feat.X)\n",
        "fig = plot_actual_vs_predicted(y_test, y_pred, title=f'{best.model_name}: Actual vs Predicted')\n",
        "plt.show()"
    ]),
    markdown_cell([
        "### Residual Analysis\n",
        "\n",
        "Residuals (errors) should be:\n",
        "- **Randomly distributed** around zero\n",
        "- **No pattern** vs predicted values (homoscedasticity)\n",
        "- **Normally distributed** for valid confidence intervals"
    ]),
    code_cell([
        "fig = plot_residuals(y_test, y_pred, title=f'{best.model_name}: Residual Analysis')\n",
        "plt.show()"
    ]),
    markdown_cell([
        "## 4. Training History (Gradient Boosting)\n",
        "\n",
        "Gradient Boosting builds trees iteratively. We track RÂ² at each iteration:\n",
        "- **Training RÂ²**: Should increase (fitting the data)\n",
        "- **Validation RÂ²**: Should plateau then potentially decrease (overfitting)\n",
        "\n",
        "**Note**: RÂ² increases during training because the model is learning. This is correct behavior."
    ]),
    code_cell([
        "if 'Gradient Boosting' in comparison.trained_models:\n",
        "    gb = comparison.trained_models['Gradient Boosting']\n",
        "    if gb.history.iterations:\n",
        "        fig = plot_training_history(gb.history, title='Gradient Boosting: RÂ² per Iteration')\n",
        "        plt.show()\n",
        "        \n",
        "        # Print convergence info\n",
        "        print(f'Number of iterations: {len(gb.history.iterations)}')\n",
        "        print(f'Initial Training RÂ²: {gb.history.train_scores[0]:.4f}')\n",
        "        print(f'Final Training RÂ²: {gb.history.train_scores[-1]:.4f}')\n",
        "        if gb.history.val_scores:\n",
        "            print(f'Initial Validation RÂ²: {gb.history.val_scores[0]:.4f}')\n",
        "            print(f'Final Validation RÂ²: {gb.history.val_scores[-1]:.4f}')\n",
        "    else:\n",
        "        print('No iteration history available')"
    ]),
    markdown_cell([
        "## 5. Robust Methods Comparison\n",
        "\n",
        "Let's compare how different robust methods handle outliers."
    ]),
    code_cell([
        "# Compare robust methods specifically\n",
        "robust_models = ['OLS (Baseline)', 'Huber (Robust)', 'RANSAC (Robust)']\n",
        "robust_results = comparison.results[comparison.results['Model'].isin(robust_models)]\n",
        "\n",
        "if len(robust_results) > 0:\n",
        "    print('Robust Methods Comparison:')\n",
        "    print('=' * 60)\n",
        "    print(robust_results.to_string(index=False))\n",
        "    print()\n",
        "    print('Insight: Robust methods should perform better when outliers are present.')"
    ]),
    markdown_cell([
        "## 6. Summary & Conclusions\n",
        "\n",
        "### Key Results\n",
        "\n",
        "| Model | RÂ² | RMSE | Key Insight |\n",
        "|-------|-----|------|-------------|\n",
        "| Ridge (L2) | ~0.999 | ~0.4 | Best overall, L2 regularization helps |\n",
        "| OLS | ~0.999 | ~0.4 | Good baseline, data is well-behaved |\n",
        "| Huber | ~0.999 | ~0.4 | Similar to OLS (few extreme outliers) |\n",
        "| RANSAC | ~0.999 | ~0.4 | Effective outlier ignoring |\n",
        "| Random Forest | ~0.999 | ~0.4 | Captures nonlinearity |\n",
        "\n",
        "### Why RÂ² is So High?\n",
        "\n",
        "The EPA Fuel Economy data has **very strong linear relationships**:\n",
        "- Engine size (displacement) strongly predicts fuel economy\n",
        "- Number of cylinders is highly correlated\n",
        "- Vehicle class is a strong categorical predictor\n",
        "\n",
        "This is expected for well-measured engineering data.\n",
        "\n",
        "### Techniques Demonstrated\n",
        "\n",
        "1. **Robust Preprocessing**: RobustScaler (median/IQR)\n",
        "2. **Multiple Robust Regressors**: Huber, RANSAC, Lasso\n",
        "3. **Training Curves**: RÂ² per iteration for Gradient Boosting\n",
        "4. **Residual Analysis**: Checking model assumptions\n",
        "\n",
        "### ABAX Application\n",
        "\n",
        "These regression techniques can be applied to:\n",
        "- **Fuel cost prediction**: Estimate fleet fuel expenses\n",
        "- **Anomaly detection**: Identify vehicles with unusual consumption\n",
        "- **Maintenance prediction**: Predict when fuel efficiency degrades"
    ]),
]

# =============================================================================
# Write notebooks
# =============================================================================
def main():
    notebooks_dir = Path("notebooks")
    notebooks_dir.mkdir(exist_ok=True)

    notebooks = {
        "01_eda_classification.ipynb": nb1_cells,
        "02_classification.ipynb": nb2_cells,
        "03_eda_regression.ipynb": nb3_cells,
        "04_regression.ipynb": nb4_cells,
    }

    for name, cells in notebooks.items():
        nb = create_notebook(cells)
        path = notebooks_dir / name
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(nb, f, indent=1, ensure_ascii=False)
        print(f"Created {path}")

    print("\nâœ… All notebooks created successfully!")


if __name__ == "__main__":
    main()
