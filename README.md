# ABAX Data Science Project

**Author:** Reza Mirzaeifard  
**Date:** December 2025  
**Purpose:** Technical assessment for ABAX Data Scientist position

---

## ğŸ“‹ Project Overview

This project demonstrates end-to-end machine learning workflows for:
1. **Driver Behavior Classification** (UAH-DriveSet)
2. **Fuel Economy Prediction** (EPA dataset)

### Key Features
- âœ… Real-world datasets (not synthetic)
- âœ… Proper train/test splitting (driver-level for classification)
- âœ… Robust regression techniques (Huber, Ridge)
- âœ… Deep learning (CNN with learning curves)
- âœ… Production-ready OOP structure
- âœ… Comprehensive notebooks with visualizations

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install -e .
```

### 2. Run Notebooks

```bash
jupyter lab notebooks/
```

**Important:** Select the **ABAX (.venv)** kernel in JupyterLab.

### 3. Run Full Pipeline

```bash
python main.py
```

---

## ğŸ“ Project Structure

```
ABAX/
â”œâ”€â”€ data/                      # Raw and processed datasets
â”‚   â”œâ”€â”€ processed/             # Cleaned data (CSV)
â”‚   â””â”€â”€ UAH-DRIVESET-v1/      # Raw driving telemetry
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ data_science_technical_task.md
â”‚   â”œâ”€â”€ evaluation_report.md
â”‚   â””â”€â”€ results_report.md
â”œâ”€â”€ logs/                      # Experiment logs
â”‚   â””â”€â”€ cnn_experiments/       # CNN training logs
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda_classification.ipynb
â”‚   â”œâ”€â”€ 02_classification.ipynb
â”‚   â”œâ”€â”€ 03_eda_regression.ipynb
â”‚   â””â”€â”€ 04_regression.ipynb
â”œâ”€â”€ results/                   # Model outputs
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ figures/               # Plots and visualizations
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ core/                  # Pydantic schemas
â”‚   â”œâ”€â”€ data/                  # Data loaders
â”‚   â”œâ”€â”€ features/              # Preprocessing
â”‚   â”œâ”€â”€ models/                # ML models
â”‚   â””â”€â”€ visualization/         # Plotting utilities
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ main.py                    # Main pipeline
â””â”€â”€ pyproject.toml            # Dependencies
```

---

## ğŸ¯ Tasks

### Task 1: Driver Behavior Classification

**Dataset:** UAH-DriveSet (40 trips, 6 drivers)  
**Goal:** Predict NORMAL / DROWSY / AGGRESSIVE

**Key Innovation:** Driver-level splitting (hold out D6) ensures generalization to new drivers.

**Results:**
- Random Forest: **92% accuracy** on held-out driver
- Logistic Regression: 88% accuracy
- 1D CNN: 90% accuracy

### Task 2: Fuel Economy Prediction

**Dataset:** EPA Fuel Economy (5,000 vehicles, 2015-2024)  
**Goal:** Predict combined MPG (continuous regression)

**Key Techniques:**
- Huber Regressor (robust to outliers)
- Ridge Regression (handles multicollinearity)
- Target encoding (high-cardinality categoricals)

**Results:**
- Random Forest: **RÂ²=0.94** (excellent!)
- Huber Regressor: RÂ²=0.89
- Linear Regression: RÂ²=0.87

---

## ğŸ”§ Technical Stack

### Core
- Python 3.9-3.11
- NumPy 1.23.5
- Pandas 2.0.3
- Scikit-learn 1.6.1

### Deep Learning
- TensorFlow 2.13.0 (macOS Intel compatible)

### Visualization
- Matplotlib 3.9.4
- Seaborn 0.13.2

### Data Quality
- Pydantic 1.x (type-safe schemas)

---

## ğŸ“Š Notebooks

### 01_eda_classification.ipynb
- UAH-DriveSet exploration
- Class distribution analysis
- Feature engineering philosophy
- Driver-level splitting rationale

### 02_classification.ipynb
- Logistic Regression baseline
- Random Forest (best: 92%)
- 1D CNN with learning curves
- Confusion matrix & feature importance

### 03_eda_regression.ipynb
- EPA dataset exploration
- Outlier detection (~10%)
- High-cardinality categoricals
- Target vs features analysis

### 04_regression.ipynb
- Linear, Huber, Ridge regressors
- Random Forest (RÂ²=0.94)
- Residual analysis
- Feature importance

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## ğŸ’¼ Business Relevance (ABAX Context)

### Fleet Management
- **Driver Safety:** Identify high-risk drivers proactively
- **Fuel Optimization:** Predict consumption for cost forecasting
- **Coaching:** Targeted feedback for drowsy/aggressive drivers

### Sustainability
- **ESG Reporting:** CO2 estimation from fuel economy
- **Route Optimization:** Based on vehicle characteristics

### Insurance
- **Risk Assessment:** Behavior-based premium adjustment

---

## ğŸ› Troubleshooting

### TensorFlow Import Error

If you see `ValueError: numpy.dtype size changed`:

1. **Restart Jupyter kernel:** `Kernel â†’ Restart Kernel`
2. **Select correct kernel:** `Kernel â†’ Change Kernel â†’ ABAX (.venv)`
3. **Verify environment:**
   ```bash
   .venv/bin/python -c "import tensorflow; print(tensorflow.__version__)"
   ```
   Should print: `2.13.0`

### NumPy Version Mismatch

```bash
# Force clean sync
rm uv.lock
uv sync
```

---

## ğŸ“ Notes

### Why NumPy 1.23.5?
TensorFlow 2.13 (last version supporting macOS Intel) requires NumPy 1.22-1.24.

### Why Pydantic 1.x?
TensorFlow 2.13 requires `typing-extensions<4.6`, incompatible with Pydantic 2.x.

### Why Driver-Level Splitting?
Random splits leak information (same driver in train/test). Holding out entire drivers ensures model generalizes to NEW drivers in production.

---

## ğŸ“§ Contact

**Reza Mirzaeifard**  
Applying for: Data Scientist @ ABAX

---

## âœ… Checklist

- [x] Classification task with real-world data
- [x] Regression task with robust techniques
- [x] Outlier handling (Huber regressor)
- [x] Categorical encoding (target encoding)
- [x] Deep learning (CNN with learning curves)
- [x] Production-ready structure (OOP + Pydantic)
- [x] Comprehensive notebooks with visualizations
- [x] Driver-level splitting for generalization
- [x] Business context (ABAX relevant)

---

**Status:** âœ… Complete and ready for review!

