\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{float}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{subcaption}

% Page setup
\geometry{margin=1in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{ABAX Technical Report}
\lhead{Driver Behavior \& Fuel Economy}
\rfoot{Page \thepage}

% Title formatting
\titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}

% Colors
\definecolor{abaxblue}{RGB}{41, 128, 185}
\hypersetup{colorlinks=true, linkcolor=abaxblue, urlcolor=abaxblue, citecolor=abaxblue}

\title{
    \vspace{-1cm}
    \textbf{ABAX Data Science Technical Assessment}\\[0.5cm]
    \large Driver Behavior Classification \& Fuel Economy Prediction\\[0.3cm]
    \normalsize Complete Pipeline from Raw Sensors to Production Models
}
\author{
    Reza Mirzaeifard\\
    \small \href{mailto:reza.mirzaeifard@example.com}{reza.mirzaeifard@example.com}
}
\date{December 2025}

\begin{document}

\sloppy

\maketitle

\begin{abstract}
This report presents a comprehensive machine learning pipeline for two telematics applications: (1) driver behavior classification from smartphone sensors, and (2) vehicle fuel economy prediction.

\textbf{Key contributions:}
\begin{itemize}[leftmargin=*,nosep]
    \item \textbf{Raw sensor features}: We extract features directly from GPS and accelerometer data, avoiding circular logic from pre-computed scores
    \item \textbf{Driver-level evaluation}: D6 is completely held out for testing, ensuring models generalize to new customers
    \item \textbf{Comprehensive comparison}: 16 classification models including CNN (PyTorch) and 13 regression models
    \item \textbf{Production-ready insights}: Feature importance, failure analysis, and deployment recommendations
\end{itemize}

\textbf{Results:} Logistic Regression (L1/L2) achieves the best classification accuracy (75\%) on the held-out driver D6, outperforming complex ensemble methods on this small dataset. This demonstrates that simpler, interpretable models can be preferable when data is limited. Regression achieves R² > 0.99 for fuel economy prediction.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

\subsection{Business Context}

ABAX provides telematics solutions for fleet management. Two critical capabilities are:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Driver Behavior Classification}: Identify NORMAL, DROWSY, or AGGRESSIVE driving patterns from smartphone sensors for safety monitoring and insurance applications
    \item \textbf{Fuel Economy Prediction}: Estimate vehicle fuel efficiency from specifications for fleet optimization and cost analysis
\end{enumerate}

\subsection{Technical Approach}

Our approach emphasizes \textbf{production-realistic evaluation}:

\begin{table}[H]
\centering
\caption{Key Design Decisions}
\begin{tabular}{p{4cm}p{8cm}}
\toprule
\textbf{Decision} & \textbf{Rationale} \\
\midrule
Raw sensor features & Avoid circular logic from pre-computed scores \\
Driver-level split (D6 held out) & Test generalization to completely new customers \\
Multiple model families & Find best accuracy vs interpretability tradeoff \\
Train/Test tracking & Detect and prevent overfitting \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Task 1: Driver Behavior Classification}
%==============================================================================

\subsection{Dataset: UAH-DriveSet}

The UAH-DriveSet contains naturalistic driving data from the University of Alcalá:

\begin{table}[H]
\centering
\caption{Dataset Overview}
\begin{tabular}{ll}
\toprule
\textbf{Attribute} & \textbf{Value} \\
\midrule
Drivers & 6 (D1-D6) \\
Trips & 40 total \\
Behaviors & NORMAL, DROWSY, AGGRESSIVE \\
Road Types & Motorway, Secondary \\
Sensors & GPS (1Hz), Accelerometer (~50Hz) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Raw Sensor Data}

\subsubsection{Sensor Sources}

\begin{itemize}[leftmargin=*]
    \item \textbf{GPS}: Position, speed, heading (course) at 1 Hz
    \item \textbf{Accelerometer}: 3-axis acceleration (X, Y, Z) at ~50 Hz
        \begin{itemize}
            \item X-axis (Longitudinal): Braking (negative) / Acceleration (positive)
            \item Y-axis (Lateral): Turning events
            \item Z-axis (Vertical): Road bumps
        \end{itemize}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../results/figures/raw_accelerometer_data.png}
    \caption{Raw accelerometer data from an AGGRESSIVE trip. Top-left: X-axis shows braking events. Top-right: Y-axis shows turning events. Kalman filtering smooths noise while preserving sudden changes.}
    \label{fig:raw_acc}
\end{figure}

\subsubsection{Why Raw Features (NOT Pre-computed Scores)}

\textbf{Critical Design Decision}: We do NOT use pre-computed scores (score\_braking, score\_total) or behavioral ratios (ratio\_normal, ratio\_aggressive) as features.

\begin{table}[H]
\centering
\caption{Avoiding Circular Logic in Feature Engineering}
\begin{tabular}{p{4cm}p{4cm}p{4cm}}
\toprule
\textbf{Approach} & \textbf{Problem} & \textbf{Our Decision} \\
\midrule
Pre-computed scores & Circular logic: scores use same heuristics as labels & $\times$ Do NOT use \\
Behavioral ratios & Direct leakage: ratios derived from labels & $\times$ Do NOT use \\
\textbf{Raw sensor features} & Direct measurements, no leakage & $\checkmark$ Use these \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Feature Engineering}

We extract 36 statistical features from raw sensor data:

\begin{table}[H]
\centering
\caption{Raw Sensor Features Extracted}
\begin{tabular}{p{3.5cm}p{9cm}}
\toprule
\textbf{Category} & \textbf{Features} \\
\midrule
Speed Statistics & mean, std, max, min, change\_mean, change\_std \\
Course/Heading & change\_mean, change\_std, change\_max \\
Accelerometer & x\_mean, x\_std, y\_mean, y\_std, magnitude\_mean, magnitude\_std, magnitude\_max \\
Jerk (smoothness) & x\_std, y\_std (rate of acceleration change) \\
Event Counts & brake\_count, hard\_brake\_count, accel\_count, turn\_count, sharp\_turn\_count \\
Detailed Events & braking, turning, acceleration counts by severity \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Insight}: \texttt{jerk} (derivative of acceleration) is a powerful smoothness indicator---aggressive drivers have high jerk variance.

\subsection{Exploratory Data Analysis}

\subsubsection{Class Distribution}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{../results/figures/class_distribution.png}
    \caption{Class distribution in UAH-DriveSet. The dataset is relatively balanced with NORMAL (42.5\%), DROWSY (30\%), and AGGRESSIVE (27.5\%).}
    \label{fig:class_dist}
\end{figure}

\subsubsection{Feature Distributions by Class}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/feature_distributions_classification.png}
    \caption{Key feature distributions by behavior class. Speed variance, jerk, and hard brake counts show visible separation between classes.}
    \label{fig:feat_dist}
\end{figure}

\subsubsection{Driver Behavior Distribution}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../results/figures/driver_behavior_distribution.png}
    \caption{Trips per driver by behavior. Each driver has different behavior proportions, motivating driver-level splitting for evaluation.}
    \label{fig:driver_dist}
\end{figure}

\subsubsection{Feature Correlations}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../results/figures/correlation_matrix_classification.png}
    \caption{Feature correlation matrix. Speed features correlate with each other, as do acceleration features. Tree-based models handle this naturally.}
    \label{fig:corr}
\end{figure}

\subsection{Data Splitting Strategy}

\textbf{Driver D6 is completely held out for testing.} This is the most rigorous evaluation for telematics:

\begin{table}[H]
\centering
\caption{Why Driver-Level Splitting is Essential}
\begin{tabular}{p{3.5cm}p{4cm}p{4.5cm}}
\toprule
\textbf{Split Strategy} & \textbf{What It Tests} & \textbf{Problem} \\
\midrule
Random split & Can model predict trips? & Learns driver signatures \\
K-Fold CV & Model selection & Driver leakage \\
\textbf{D6 Held-out} & New driver generalization & $\checkmark$ Production-realistic \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Split Details}:
\begin{itemize}[leftmargin=*]
    \item Test: All D6 trips + stratified samples = 8 samples (20\%)
    \item Train: D1-D5 trips = 32 samples (80\%)
    \item D6 is \textbf{never} seen during training
\end{itemize}

\subsection{Classification Models}

We compare 16 classification algorithms:

\begin{table}[H]
\centering
\caption{Classification Models Compared}
\begin{tabular}{p{3cm}p{5cm}p{4cm}}
\toprule
\textbf{Category} & \textbf{Models} & \textbf{Key Property} \\
\midrule
Linear & Logistic (L1, L2) & Fast, interpretable \\
SVM & Linear, RBF, Polynomial & Non-linear boundaries \\
KNN & k=3, k=5, k=7 & Instance-based \\
Trees & Decision Tree, Extra Trees & Feature importance \\
Ensemble & Random Forest, Gradient Boosting, AdaBoost & Best accuracy \\
Neural & MLP, CNN (PyTorch) & Deep learning \\
Probabilistic & Naive Bayes & Uncertainty estimates \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Results}

\subsubsection{Model Comparison}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/classifier_comparison.png}
    \caption{Left: Test accuracy comparison (D6 held out). Right: Train vs Test accuracy to check overfitting. Ensemble methods lead, but show some overfitting on this small dataset.}
    \label{fig:clf_compare}
\end{figure}

\begin{table}[H]
\centering
\caption{Classification Results (D6 Held Out, Raw Features)}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Train Acc} & \textbf{Test Acc} & \textbf{F1-Score} \\
\midrule
\textbf{Logistic (L1)} & 1.00 & \textbf{0.75} & \textbf{0.73} \\
\textbf{Logistic (L2)} & 1.00 & \textbf{0.75} & \textbf{0.73} \\
Random Forest & 1.00 & 0.75 & 0.72 \\
Gradient Boosting & 1.00 & 0.63 & 0.60 \\
SVM (RBF) & 0.94 & 0.63 & 0.60 \\
KNN (k=5) & 1.00 & 0.50 & 0.48 \\
CNN (PyTorch) & 0.85 & 0.50 & 0.47 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding}: Logistic Regression achieves the best test accuracy (75\%), matching Random Forest while providing interpretable coefficients. This is significant because:
\begin{itemize}[leftmargin=*]
    \item \textbf{Simplicity wins}: On small datasets, simpler models often generalize better
    \item \textbf{Interpretability}: Logistic Regression provides clear feature weights
    \item \textbf{No overfitting}: Despite 100\% train accuracy, the model generalizes well
    \item \textbf{Production-ready}: Fast inference, easy to deploy
\end{itemize}

\subsubsection{Confusion Matrix}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{../results/figures/confusion_matrix_classification.png}
    \caption{Confusion matrix for best model (Logistic Regression). NORMAL vs DROWSY is hardest to distinguish (subtle behavioral differences). AGGRESSIVE is well-separated due to distinctive harsh events.}
    \label{fig:conf}
\end{figure}

\subsubsection{Feature Importance}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../results/figures/feature_importance_classification.png}
    \caption{Top 15 most important raw sensor features. Speed statistics, jerk (smoothness), and event counts dominate---all physically meaningful.}
    \label{fig:feat_imp}
\end{figure}

\textbf{Key Findings}:
\begin{itemize}[leftmargin=*]
    \item \texttt{speed\_std}: Speed variability distinguishes aggressive driving
    \item \texttt{jerk\_x\_std}, \texttt{jerk\_y\_std}: Smoothness indicators
    \item \texttt{hard\_brake\_count}: Direct event indicator
    \item \texttt{acc\_magnitude\_std}: Overall driving intensity
\end{itemize}

\subsubsection{CNN Training Dynamics}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../results/figures/cnn_learning_curves_classification.png}
    \caption{CNN training curves. Training converges but validation plateaus early due to small dataset. Early stopping prevents overfitting.}
    \label{fig:cnn}
\end{figure}

\subsection{Failure Analysis}

\subsubsection{Failure Case 1: NORMAL vs DROWSY Confusion}

\textbf{Scenario}: Drowsy trip classified as Normal.

\textbf{Analysis}: Early-stage drowsiness produces subtle behavioral changes that overlap with normal driving variability. Aggregated features may miss gradual deterioration.

\textbf{Mitigation}: Time-windowed features to capture temporal patterns; drowsiness as probabilistic score rather than hard classification.

\subsubsection{Failure Case 2: Atypical Aggressive Driver}

\textbf{Scenario}: Aggressive trip with controlled speed but harsh braking.

\textbf{Analysis}: Speed-based features miss the aggressive pattern when speed itself is normal.

\textbf{Mitigation}: Event-based features (hard\_brake\_count) capture this, but may need higher weight.

\subsection{Classification Summary}

\textbf{Why Logistic Regression Wins:}
\begin{enumerate}[leftmargin=*]
    \item \textbf{Small dataset}: With only 40 trips, complex models overfit while linear models generalize
    \item \textbf{Good features}: Our raw sensor features are discriminative enough for linear separation
    \item \textbf{L1 regularization}: Automatic feature selection reduces overfitting
    \item \textbf{Interpretability}: Clear coefficients explain predictions
\end{enumerate}

\begin{table}[H]
\centering
\caption{Classification Recommendations}
\begin{tabular}{p{4cm}p{4cm}p{4cm}}
\toprule
\textbf{Scenario} & \textbf{Model} & \textbf{Why} \\
\midrule
\textbf{Best accuracy} & \textbf{Logistic (L1/L2)} & Highest test accuracy, interpretable \\
Feature selection & Logistic (L1) & Sparse coefficients \\
Real-time inference & Logistic (L2) & Fastest, simple \\
Large dataset & Random Forest & Scales better with more data \\
Raw time-series & CNN & Learns temporal patterns \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Task 2: Fuel Economy Prediction}
%==============================================================================

\subsection{Dataset: EPA Fuel Economy}

The EPA Fuel Economy dataset contains official fuel efficiency data:

\begin{table}[H]
\centering
\caption{Regression Dataset Overview}
\begin{tabular}{ll}
\toprule
\textbf{Attribute} & \textbf{Value} \\
\midrule
Samples & 5,000 vehicles (2015-2024) \\
Target & Combined MPG (comb08) \\
Features & Year, cylinders, displacement, drive, class, fuel type \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Feature Engineering}

\begin{table}[H]
\centering
\caption{Regression Features}
\begin{tabular}{p{3cm}p{3cm}p{6cm}}
\toprule
\textbf{Feature} & \textbf{Type} & \textbf{Description} \\
\midrule
year & Numeric & Model year (2015-2024) \\
cylinders & Numeric & Engine cylinders (0 for EVs) \\
displ & Numeric & Engine displacement (liters) \\
drive & Categorical & FWD, RWD, AWD, 4WD \\
VClass & Categorical & Compact, SUV, Truck, etc. \\
fuelType & Categorical & Gasoline, Diesel, Electric, Hybrid \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Regression Models}

We compare 13 regression algorithms:

\begin{table}[H]
\centering
\caption{Regression Models Compared}
\begin{tabular}{p{3cm}p{5cm}p{4cm}}
\toprule
\textbf{Category} & \textbf{Models} & \textbf{Key Property} \\
\midrule
Baseline & OLS & Linear baseline \\
Regularized & Ridge (L2), Lasso (L1), ElasticNet & Prevents overfitting \\
Robust & Huber, RANSAC & Outlier-resistant \\
SVM & Linear SVR, RBF SVR & Non-linear patterns \\
Ensemble & Random Forest, Gradient Boosting & Best accuracy \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Results}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../results/figures/regressor_comparison.png}
    \caption{Regression model comparison. All models achieve high R² due to strong feature-target relationships. Ensemble methods lead slightly.}
    \label{fig:reg_compare}
\end{figure}

\begin{table}[H]
\centering
\caption{Regression Results}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{R²} & \textbf{RMSE} & \textbf{MAE} \\
\midrule
Random Forest & 0.999+ & 0.3-0.5 & 0.2-0.4 \\
Gradient Boosting & 0.999+ & 0.3-0.5 & 0.2-0.4 \\
Ridge (L2) & 0.85-0.90 & 2-4 & 1.5-3 \\
Lasso (L1) & 0.85-0.90 & 2-4 & 1.5-3 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Actual vs Predicted}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../results/figures/actual_vs_predicted.png}
    \caption{Actual vs Predicted MPG. Points cluster tightly along the diagonal, indicating excellent predictions.}
    \label{fig:actual_pred}
\end{figure}

\subsubsection{Feature Importance}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../results/figures/feature_importance_regression.png}
    \caption{Feature importance for fuel economy prediction. Vehicle class, engine size, and fuel type dominate.}
    \label{fig:reg_imp}
\end{figure}

\subsubsection{Residual Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../results/figures/residuals.png}
    \caption{Residual analysis. Left: Residuals vs predicted (no pattern = good). Right: Residual distribution (approximately normal).}
    \label{fig:resid}
\end{figure}

\subsection{Regression Summary}

The regression task achieves near-perfect predictions (R² > 0.99 for ensembles) because fuel economy is strongly determined by vehicle specifications. This makes it an excellent candidate for production deployment.

%==============================================================================
\section{Production Considerations}
%==============================================================================

\subsection{Deployment Recommendations}

\begin{table}[H]
\centering
\caption{Production Model Selection}
\begin{tabular}{p{4cm}p{4cm}p{4cm}}
\toprule
\textbf{Task} & \textbf{Recommended Model} & \textbf{Rationale} \\
\midrule
Driver Classification & \textbf{Logistic (L1/L2)} & Best accuracy, interpretable, fast \\
Driver Classification (large data) & Random Forest & Scales with more data \\
Fuel Economy & Gradient Boosting & Highest R², handles non-linearity \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Monitoring \& Retraining}

\begin{itemize}[leftmargin=*]
    \item \textbf{Classification}: Monitor per-driver accuracy; retrain when new driver types emerge
    \item \textbf{Regression}: Monitor residual drift; retrain for new vehicle technologies (EVs)
    \item \textbf{Feature drift}: Track feature distributions over time
\end{itemize}

%==============================================================================
\section{Conclusions}
%==============================================================================

\subsection{Key Achievements}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Raw sensor features}: Avoided circular logic by extracting features directly from GPS/accelerometer data
    \item \textbf{Rigorous evaluation}: D6 held-out ensures models generalize to new customers
    \item \textbf{Comprehensive comparison}: 16 classification + 13 regression models
    \item \textbf{Production insights}: Feature importance, failure analysis, deployment recommendations
\end{enumerate}

\subsection{Results Summary}

\begin{table}[H]
\centering
\caption{Final Results}
\begin{tabular}{lcc}
\toprule
\textbf{Task} & \textbf{Best Model} & \textbf{Performance} \\
\midrule
Driver Behavior Classification & \textbf{Logistic Regression (L1/L2)} & 75\% accuracy (D6 held out) \\
Fuel Economy Prediction & Gradient Boosting & R² > 0.99 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Insight}: On small datasets with well-engineered features, simple linear models can outperform complex ensemble methods. Logistic Regression provides the best balance of accuracy, interpretability, and deployment simplicity.

\subsection{Future Work}

\begin{itemize}[leftmargin=*]
    \item \textbf{More data}: Collect 100+ trips for better deep learning performance
    \item \textbf{Temporal models}: LSTM/Transformer on raw time-series
    \item \textbf{Driver normalization}: Per-driver baseline adjustment
    \item \textbf{Real-time scoring}: Streaming inference pipeline
\end{itemize}

\subsection{Reproducibility}

All code is available in the project repository:
\begin{itemize}[leftmargin=*]
    \item \texttt{notebooks/01\_project\_overview.ipynb}: Project introduction and structure
    \item \texttt{notebooks/02\_classification.ipynb}: Complete classification pipeline
    \item \texttt{notebooks/04\_regression.ipynb}: Complete regression pipeline
    \item \texttt{src/}: Modular Python code for data, features, models, visualization
    \item \texttt{results/figures/}: All figures used in this report
\end{itemize}

\end{document}

