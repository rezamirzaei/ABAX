\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{float}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{multirow}

% Page setup
\geometry{margin=1in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{ABAX Technical Report}
\lhead{Driver Behavior \& Fuel Economy}
\rfoot{Page \thepage}

% Title formatting
\titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}

% Colors
\definecolor{abaxblue}{RGB}{41, 128, 185}
\definecolor{successgreen}{RGB}{39, 174, 96}
\definecolor{warningorange}{RGB}{230, 126, 34}
\hypersetup{colorlinks=true, linkcolor=abaxblue, urlcolor=abaxblue, citecolor=abaxblue}

\title{
    \vspace{-1cm}
    \textbf{ABAX Data Science Technical Assessment}\\[0.5cm]
    \large Driver Behavior Classification \& Fuel Economy Prediction\\[0.3cm]
    \normalsize Complete Machine Learning Pipeline from Raw Sensors to Production Models
}
\author{
    Reza Mirzaeifard\\
    \small \href{mailto:reza.mirzaeifard@gmail.com}{reza.mirzaeifard@example.com}
}
\date{December 2025}

\begin{document}

\maketitle

\begin{abstract}
This report presents a comprehensive machine learning pipeline for two telematics applications: (1) driver behavior classification from smartphone sensors, and (2) vehicle fuel economy prediction.

\textbf{Key Contributions:}
\begin{itemize}[leftmargin=*,nosep]
    \item \textbf{Raw sensor features}: Extract 36 features directly from GPS and accelerometer data, avoiding circular logic from pre-computed scores
    \item \textbf{Driver-level evaluation}: Driver D6 completely held out for testing, ensuring models generalize to new customers
    \item \textbf{Comprehensive model comparison}: 18 classification models (including MCP, SCAD, CNN) and 13 regression models
    \item \textbf{Advanced regularization}: Implement MCP and SCAD penalties for nearly unbiased sparse feature selection
    \item \textbf{Production-ready insights}: Feature importance, failure analysis, and deployment recommendations
\end{itemize}

\textbf{Results:} Sparse linear models (Logistic L1, SCAD) achieve \textbf{87.5\% classification accuracy} on the held-out driver D6, outperforming complex ensemble methods. This demonstrates that simpler, interpretable models with proper regularization are preferable when data is limited. Regression achieves R² = 0.94 for fuel economy prediction with Random Forest.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

\subsection{Business Context}

ABAX provides telematics solutions for fleet management, enabling companies to monitor vehicle usage, driver behavior, and operational efficiency. Two critical machine learning capabilities are:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Driver Behavior Classification}: Identify NORMAL, DROWSY, or AGGRESSIVE driving patterns from smartphone sensors for:
    \begin{itemize}
        \item \textbf{Safety monitoring}: Alert fleet managers to dangerous driving
        \item \textbf{Insurance pricing}: Risk-based premiums for usage-based insurance
        \item \textbf{Driver coaching}: Targeted feedback to improve behavior
    \end{itemize}

    \item \textbf{Fuel Economy Prediction}: Estimate vehicle fuel efficiency from specifications for:
    \begin{itemize}
        \item \textbf{Fleet optimization}: Select fuel-efficient vehicles
        \item \textbf{Cost analysis}: Predict fuel costs for different vehicle types
        \item \textbf{Environmental compliance}: Track carbon footprint
    \end{itemize}
\end{enumerate}

\subsection{Technical Challenges}

\subsubsection{Classification Challenges}
\begin{itemize}[leftmargin=*]
    \item \textbf{Small dataset}: Only 40 trips from 6 drivers---too small for complex models
    \item \textbf{Driver heterogeneity}: Each driver has unique driving ``signatures''
    \item \textbf{Subtle distinctions}: NORMAL vs DROWSY driving is hard to distinguish
    \item \textbf{Circular logic risk}: Pre-computed scores use same heuristics as labels
\end{itemize}

\subsubsection{Regression Challenges}
\begin{itemize}[leftmargin=*]
    \item \textbf{Mixed data types}: Numeric (displacement) and categorical (fuel type)
    \item \textbf{Non-linear relationships}: MPG varies non-linearly with engine size
    \item \textbf{Technology evolution}: Electric vehicles have different patterns
\end{itemize}

\subsection{Our Approach}

Our approach emphasizes \textbf{production-realistic evaluation} and \textbf{clean code architecture}:

\begin{table}[H]
\centering
\caption{Key Design Decisions}
\begin{tabular}{p{4.5cm}p{8cm}}
\toprule
\textbf{Decision} & \textbf{Rationale} \\
\midrule
Raw sensor features only & Avoid circular logic from pre-computed scores that use same heuristics as labels \\
Driver-level split (D6 held out) & Test generalization to completely new customers, not just new trips \\
Multiple model families (18+) & Find optimal accuracy vs interpretability vs complexity tradeoff \\
Train/Test accuracy tracking & Detect and prevent overfitting on small datasets \\
Modular code in \texttt{src/} & Clean, testable, reusable functions---notebooks only call functions \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Task 1: Driver Behavior Classification}
%==============================================================================

\subsection{Dataset: UAH-DriveSet}

The UAH-DriveSet contains naturalistic driving data collected by the University of Alcalá, Spain. Drivers performed trips under three behavioral conditions using a smartphone mounted on the dashboard.

\begin{table}[H]
\centering
\caption{UAH-DriveSet Overview}
\begin{tabular}{ll}
\toprule
\textbf{Attribute} & \textbf{Value} \\
\midrule
Source & University of Alcalá (naturalistic driving study) \\
Drivers & 6 (labeled D1--D6) \\
Total Trips & 40 \\
Behaviors & NORMAL (42.5\%), DROWSY (30\%), AGGRESSIVE (27.5\%) \\
Road Types & Motorway, Secondary roads \\
Sensors & GPS (1 Hz), Accelerometer ($\sim$50 Hz) \\
Data Files & RAW\_GPS.txt, RAW\_ACCELEROMETERS.txt, EVENTS\_INERTIAL.txt \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Understanding Raw Sensor Data}

\subsubsection{Sensor Sources and Sampling Rates}

\begin{table}[H]
\centering
\caption{Sensor Data Description}
\begin{tabular}{p{3cm}p{2cm}p{7cm}}
\toprule
\textbf{Sensor} & \textbf{Frequency} & \textbf{Data Captured} \\
\midrule
GPS & 1 Hz & Latitude, longitude, speed (km/h), course/heading (degrees), altitude \\
Accelerometer & $\sim$50 Hz & 3-axis acceleration (X, Y, Z) in g-forces, both raw and Kalman-filtered \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Phone Orientation and Axis Meaning}

The smartphone is mounted horizontally (landscape) on the dashboard. The accelerometer axes correspond to:

\begin{itemize}[leftmargin=*]
    \item \textbf{X-axis (Longitudinal)}: Points forward/backward along the vehicle
    \begin{itemize}
        \item Negative values $\rightarrow$ \textbf{Braking} (deceleration pushes phone forward)
        \item Positive values $\rightarrow$ \textbf{Acceleration} (acceleration pushes phone backward)
    \end{itemize}
    \item \textbf{Y-axis (Lateral)}: Points left/right across the vehicle
    \begin{itemize}
        \item Non-zero values $\rightarrow$ \textbf{Turning} (lateral forces during curves)
    \end{itemize}
    \item \textbf{Z-axis (Vertical)}: Points up/down
    \begin{itemize}
        \item Baseline $\approx$ 1g (gravity)
        \item Deviations $\rightarrow$ Road bumps, inclines
    \end{itemize}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/raw_accelerometer_data.png}
    \caption{Raw accelerometer data from an AGGRESSIVE trip. \textbf{Top-left}: X-axis shows braking events (negative spikes). \textbf{Top-right}: Y-axis shows turning events. \textbf{Bottom-left}: Acceleration magnitude. \textbf{Bottom-right}: GPS speed. Light colors show raw data; dark colors show Kalman-filtered data that smooths noise while preserving sudden changes.}
    \label{fig:raw_acc}
\end{figure}

\subsubsection{Event Detection Logic}

The DriveSafe algorithm detects driving events by applying thresholds to Kalman-filtered accelerometer data:

\begin{table}[H]
\centering
\caption{Event Detection Thresholds}
\begin{tabular}{p{2.5cm}p{1.5cm}p{4cm}p{4.5cm}}
\toprule
\textbf{Event Type} & \textbf{Axis} & \textbf{Condition} & \textbf{Physical Meaning} \\
\midrule
Braking & X & acc\_x $<$ $-$0.1g to $-$0.3g & Deceleration \\
Acceleration & X & acc\_x $>$ +0.1g to +0.3g & Acceleration \\
Turning & Y & $|$acc\_y$|$ $>$ 0.1g to 0.3g & Lateral force \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Severity Levels}:
\begin{itemize}[leftmargin=*]
    \item \textbf{Low}: Gentle maneuver (e.g., coasting to a stop at red light)
    \item \textbf{Medium}: Normal maneuver (e.g., regular braking at intersection)
    \item \textbf{High}: Harsh maneuver (e.g., emergency braking, sharp swerve)
\end{itemize}

\subsubsection{Why Kalman Filtering?}

Raw accelerometer data contains significant noise from road vibrations, engine vibrations, and sensor noise. The Kalman filter is a recursive algorithm that:
\begin{enumerate}[leftmargin=*]
    \item Predicts the next state based on physics (acceleration model)
    \item Updates the prediction with the noisy measurement
    \item Produces a smooth estimate that preserves sudden changes (events)
\end{enumerate}

\subsection{Feature Engineering}

\subsubsection{Why Raw Features (NOT Pre-computed Scores)}

\textbf{Critical Design Decision}: We do \textbf{NOT} use pre-computed scores (score\_braking, score\_total) or behavioral ratios (ratio\_normal, ratio\_aggressive) as features.

\begin{table}[H]
\centering
\caption{Avoiding Circular Logic in Feature Engineering}
\begin{tabular}{p{4cm}p{5cm}p{3cm}}
\toprule
\textbf{Approach} & \textbf{Problem} & \textbf{Our Decision} \\
\midrule
Pre-computed scores & Circular logic: scores computed using same heuristics as behavior labels & $\times$ Avoid \\
Behavioral ratios & Direct leakage: ratios derived from labels & $\times$ Avoid \\
\textbf{Raw sensor statistics} & Direct measurements, no leakage, honest evaluation & $\checkmark$ \textbf{Use} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Features Extracted (36 Total)}

We extract statistical summaries from each trip's raw sensor data:

\begin{table}[H]
\centering
\caption{Raw Sensor Features by Category}
\begin{tabular}{p{3cm}p{5cm}p{4.5cm}}
\toprule
\textbf{Category} & \textbf{Features} & \textbf{Physical Meaning} \\
\midrule
Speed Statistics & mean, std, max, min & Driving intensity \\
Speed Changes & change\_mean, change\_std & Accel/decel patterns \\
Course/Heading & change\_mean, std, max & Lane changes, turns \\
Acceleration & mean, std for X/Y axes & Core behavior signal \\
Acc. Magnitude & mean, std, max & Ride ``bumpiness'' \\
Jerk & x\_std, y\_std & Smoothness indicator \\
Event Counts & brake, turn, hard events & Discrete summaries \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Why Jerk is Important}: Jerk = $\frac{d(\text{acceleration})}{dt}$. Aggressive drivers have high jerk variance because they:
\begin{itemize}[leftmargin=*]
    \item Brake suddenly instead of gradually
    \item Accelerate abruptly from stops
    \item Make sharp steering corrections
\end{itemize}

\subsection{Exploratory Data Analysis}

\subsubsection{Class Distribution}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/figures/class_distribution.png}
    \caption{Class distribution in UAH-DriveSet. The dataset is relatively balanced: NORMAL (17 trips, 42.5\%), DROWSY (12 trips, 30\%), AGGRESSIVE (11 trips, 27.5\%). Minor imbalance handled with class weighting.}
    \label{fig:class_dist}
\end{figure}

\subsubsection{Feature Distributions by Behavior Class}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/feature_distributions_classification.png}
    \caption{Key feature distributions by behavior class. \textbf{Observations}: (1) speed\_std is higher for AGGRESSIVE; (2) jerk\_x\_std separates AGGRESSIVE from others; (3) hard\_brake\_count is highest for AGGRESSIVE; (4) NORMAL and DROWSY overlap significantly, making them harder to distinguish.}
    \label{fig:feat_dist}
\end{figure}

\subsubsection{Driver Behavior Heterogeneity}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../results/figures/driver_behavior_distribution.png}
    \caption{Trips per driver by behavior. Each driver has a different mix of behaviors. This heterogeneity means random splitting would leak driver ``signatures'' into the test set---we must use driver-level splitting.}
    \label{fig:driver_dist}
\end{figure}

\subsubsection{Feature Correlations}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../results/figures/correlation_matrix_classification.png}
    \caption{Feature correlation matrix. Speed features correlate with each other; acceleration features correlate with each other. L1 regularization handles this by selecting one feature from correlated groups.}
    \label{fig:corr}
\end{figure}

\subsubsection{Behavior Comparison}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/behavior_comparison_raw.png}
    \caption{Feature means by behavior class. AGGRESSIVE shows clearly higher values for speed\_std, hard\_brake\_count, sharp\_turn\_count, and jerk\_x\_std. DROWSY and NORMAL have similar profiles, explaining classification difficulty.}
    \label{fig:behavior_compare}
\end{figure}

\subsection{Data Splitting Strategy}

\textbf{Driver D6 is completely held out for testing.} This is the most rigorous evaluation for telematics applications.

\begin{table}[H]
\centering
\caption{Why Driver-Level Splitting is Essential}
\begin{tabular}{p{3.5cm}p{4.5cm}p{4.5cm}}
\toprule
\textbf{Split Strategy} & \textbf{What It Tests} & \textbf{Problem} \\
\midrule
Random split & Can model predict trips? & Learns driver signatures, not behaviors \\
Stratified K-Fold & Model selection & Driver leakage across folds \\
\textbf{D6 Held-out} & \textbf{New driver generalization} & $\checkmark$ Production-realistic \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Final Split}:
\begin{itemize}[leftmargin=*]
    \item \textbf{Training}: 32 samples (80\%) from drivers D1--D5
    \item \textbf{Testing}: 8 samples (20\%) = all D6 trips + stratified samples
    \item \textbf{Guarantee}: D6 is \textbf{never} seen during training
\end{itemize}

\subsection{Classification Models}

We compare 18 classification algorithms across multiple families:

\begin{table}[H]
\centering
\caption{Classification Models Compared (18 Total)}
\begin{tabular}{p{2.5cm}p{5.5cm}p{4.5cm}}
\toprule
\textbf{Category} & \textbf{Models} & \textbf{Key Property} \\
\midrule
Linear & Logistic (L1, L2, ElasticNet) & Fast, interpretable coefficients \\
Sparse & \textbf{Logistic (MCP, SCAD)} & Nearly unbiased sparse estimates \\
SVM & Linear, RBF, Polynomial & Kernel methods, non-linear \\
KNN & k=3, k=5, k=7 & Instance-based, interpretable \\
Trees & Decision Tree, Extra Trees & Feature importance \\
Ensemble & Random Forest, Gradient Boosting, AdaBoost & Often highest accuracy \\
Neural & MLP, \textbf{CNN (PyTorch)} & Deep learning \\
Probabilistic & Naive Bayes & Fast, uncertainty estimates \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Advanced Regularization: MCP and SCAD}

Beyond standard L1 (Lasso) regularization, we implement advanced penalties:

\begin{table}[H]
\centering
\caption{Regularization Penalties Compared}
\begin{tabular}{p{2.5cm}p{5cm}p{5cm}}
\toprule
\textbf{Penalty} & \textbf{Behavior} & \textbf{Best For} \\
\midrule
L1 (Lasso) & Shrinks all coefficients toward zero & General sparsity, but biases large coefficients \\
\textbf{MCP} & Minimax Concave Penalty---nearly unbiased for large coefficients & Strong feature selection \\
\textbf{SCAD} & Smoothly Clipped Absolute Deviation---unbiased for large coefficients & Oracle properties \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Classification Results}

\subsubsection{Model Comparison}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/classifier_comparison.png}
    \caption{\textbf{Left}: Test accuracy comparison (D6 held out). Sparse linear models achieve highest accuracy. \textbf{Right}: Train vs Test accuracy---large gaps indicate overfitting. Complex models (Random Forest, Gradient Boosting) overfit on this small dataset.}
    \label{fig:clf_compare}
\end{figure}

\begin{table}[H]
\centering
\caption{Classification Results (D6 Held Out, Raw Features Only)}
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Train Acc} & \textbf{Test Acc} & \textbf{F1-Score} & \textbf{Overfit Gap} \\
\midrule
\textbf{Logistic (L1)} & 1.000 & \textbf{0.875} & \textbf{0.863} & 0.125 \\
\textbf{Logistic (SCAD)} & 0.875 & \textbf{0.875} & \textbf{0.863} & 0.000 \\
SVM (Linear) & 1.000 & 0.875 & 0.871 & 0.125 \\
AdaBoost & 0.938 & 0.875 & 0.871 & 0.063 \\
Logistic (L2) & 1.000 & 0.750 & 0.748 & 0.250 \\
Logistic (MCP) & 0.969 & 0.750 & 0.709 & 0.219 \\
Random Forest & 1.000 & 0.750 & 0.750 & 0.250 \\
Extra Trees & 1.000 & 0.750 & 0.750 & 0.250 \\
MLP & 1.000 & 0.750 & 0.748 & 0.250 \\
Gradient Boosting & 1.000 & 0.625 & 0.604 & 0.375 \\
SVM (RBF) & 0.969 & 0.625 & 0.604 & 0.344 \\
KNN (k=3) & 0.750 & 0.625 & 0.604 & 0.125 \\
Naive Bayes & 0.969 & 0.625 & 0.630 & 0.344 \\
Decision Tree & 1.000 & 0.500 & 0.392 & 0.500 \\
KNN (k=5) & 1.000 & 0.500 & 0.502 & 0.500 \\
CNN (PyTorch) & $\sim$0.85 & $\sim$0.50 & $\sim$0.47 & $\sim$0.35 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding}: \textcolor{successgreen}{\textbf{Sparse linear models (L1, SCAD) achieve 87.5\% test accuracy}}, outperforming complex ensemble methods. This is significant because:
\begin{itemize}[leftmargin=*]
    \item \textbf{Simplicity wins}: On small datasets (40 trips), simpler models generalize better
    \item \textbf{SCAD advantage}: No overfitting gap (Train = Test = 87.5\%)
    \item \textbf{Interpretability}: Clear feature coefficients explain predictions
    \item \textbf{Production-ready}: Sub-millisecond inference, easy deployment
\end{itemize}

\subsubsection{Confusion Matrix Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{../results/figures/confusion_matrix_classification.png}
    \caption{Confusion matrix for best model (Logistic L1, 87.5\% accuracy). AGGRESSIVE is well-separated due to distinctive harsh events. NORMAL vs DROWSY shows some confusion due to subtle behavioral differences.}
    \label{fig:conf}
\end{figure}

\textbf{Error Analysis}:
\begin{itemize}[leftmargin=*]
    \item \textbf{AGGRESSIVE}: Rarely confused---harsh events (hard brakes, sharp turns) are distinctive
    \item \textbf{NORMAL vs DROWSY}: Most confused pair---early-stage drowsiness resembles relaxed normal driving
\end{itemize}

\subsubsection{Feature Importance}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../results/figures/feature_importance_classification.png}
    \caption{Top 15 most important raw sensor features (from Logistic Regression coefficients). All top features have clear physical meaning: speed variance, jerk (smoothness), and event counts dominate.}
    \label{fig:feat_imp}
\end{figure}

\textbf{Top Features (Physical Interpretation)}:
\begin{enumerate}[leftmargin=*]
    \item \texttt{speed\_std}: Speed variability---aggressive drivers have erratic speeds
    \item \texttt{jerk\_x\_std}: Longitudinal smoothness---aggressive $=$ jerky braking/acceleration
    \item \texttt{hard\_brake\_count}: Direct harsh event indicator
    \item \texttt{acc\_magnitude\_std}: Overall driving intensity
    \item \texttt{sharp\_turn\_count}: Harsh steering events
    \item \texttt{jerk\_y\_std}: Lateral smoothness---aggressive $=$ jerky steering
\end{enumerate}

\subsubsection{CNN Training Dynamics}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../results/figures/cnn_learning_curves_classification.png}
    \caption{CNN training curves. Training loss decreases but validation accuracy plateaus early due to small dataset (32 training samples). Early stopping prevents further overfitting.}
    \label{fig:cnn}
\end{figure}

\textbf{Why CNN Doesn't Win}:
\begin{itemize}[leftmargin=*]
    \item \textbf{Small dataset}: 32 training samples is insufficient for deep learning
    \item \textbf{Aggregated features}: CNN designed for sequential data; we use trip-level aggregates
    \item \textbf{Future potential}: With raw time-series and 100+ trips, CNN would likely excel
\end{itemize}

\subsection{Failure Analysis}

\subsubsection{Failure Case 1: DROWSY $\rightarrow$ NORMAL Misclassification}

\textbf{Scenario}: Early-stage drowsy trip classified as normal.

\textbf{Root Cause}: Drowsiness manifests gradually---early stages resemble relaxed normal driving with moderate speeds and few harsh events.

\textbf{Mitigation}:
\begin{itemize}[leftmargin=*]
    \item Time-windowed features to capture temporal deterioration
    \item Drowsiness as probabilistic score rather than hard classification
    \item Additional features: lane position variance, reaction time
\end{itemize}

\subsubsection{Failure Case 2: Atypical AGGRESSIVE Driver}

\textbf{Scenario}: Aggressive trip with controlled speed but harsh braking.

\textbf{Root Cause}: Speed-based features miss aggressive patterns when speed is normal; aggression manifests only in braking/turning.

\textbf{Mitigation}:
\begin{itemize}[leftmargin=*]
    \item Higher weight for event-based features (hard\_brake\_count)
    \item Ratio features: events per kilometer
\end{itemize}

\subsection{Classification Summary}

\textbf{Why Sparse Linear Models Win}:
\begin{enumerate}[leftmargin=*]
    \item \textbf{Small dataset}: 40 trips $\rightarrow$ complex models overfit
    \item \textbf{Good features}: 36 raw sensor features provide sufficient discriminative power
    \item \textbf{L1/SCAD regularization}: Automatic feature selection reduces overfitting
    \item \textbf{Nearly unbiased}: SCAD doesn't shrink large (important) coefficients
    \item \textbf{Interpretability}: Clear coefficients enable business explanations
\end{enumerate}

\begin{table}[H]
\centering
\caption{Classification Model Recommendations}
\begin{tabular}{p{4cm}p{4cm}p{4.5cm}}
\toprule
\textbf{Scenario} & \textbf{Recommended Model} & \textbf{Rationale} \\
\midrule
\textbf{Best accuracy + interpretability} & \textbf{Logistic (L1) or SCAD} & 87.5\% accuracy, sparse coefficients \\
Feature selection & Logistic (L1) & Sparse, zero coefficients for irrelevant features \\
No overfitting & Logistic (SCAD) & Train = Test accuracy \\
Large dataset ($>$100 trips) & Random Forest & Scales better with more data \\
Raw time-series data & CNN (PyTorch) & Learns temporal patterns automatically \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Task 2: Fuel Economy Prediction}
%==============================================================================

\subsection{Dataset: EPA Fuel Economy}

The EPA Fuel Economy dataset contains official fuel efficiency ratings for vehicles sold in the United States.

\begin{table}[H]
\centering
\caption{Regression Dataset Overview}
\begin{tabular}{ll}
\toprule
\textbf{Attribute} & \textbf{Value} \\
\midrule
Source & U.S. Environmental Protection Agency \\
Samples & $\sim$5,000 vehicles (2015--2024) \\
Target Variable & Combined MPG (comb08) \\
Features & Year, cylinders, displacement, drive type, vehicle class, fuel type \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Feature Engineering}

\begin{table}[H]
\centering
\caption{Regression Features}
\begin{tabular}{p{3cm}p{2.5cm}p{7cm}}
\toprule
\textbf{Feature} & \textbf{Type} & \textbf{Description} \\
\midrule
year & Numeric & Model year (2015--2024); newer vehicles often more efficient \\
cylinders & Numeric & Engine cylinders (0 for EVs); more cylinders $\rightarrow$ lower MPG \\
displ & Numeric & Engine displacement (liters); larger engines $\rightarrow$ lower MPG \\
drive & Categorical & FWD, RWD, AWD, 4WD; affects drivetrain efficiency \\
VClass & Categorical & Compact, Midsize, SUV, Truck; size affects aerodynamics \\
fuelType & Categorical & Gasoline, Diesel, Electric, Hybrid; technology differences \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Regression Models}

We compare 13 regression algorithms:

\begin{table}[H]
\centering
\caption{Regression Models Compared}
\begin{tabular}{p{3cm}p{5.5cm}p{4cm}}
\toprule
\textbf{Category} & \textbf{Models} & \textbf{Key Property} \\
\midrule
Baseline & OLS Linear Regression & Simple baseline \\
Regularized & Ridge (L2), Lasso (L1), ElasticNet & Prevents overfitting \\
Robust & Huber, RANSAC & Outlier-resistant \\
SVM & Linear SVR, RBF SVR & Non-linear patterns \\
Ensemble & Random Forest, Gradient Boosting & Often highest accuracy \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Regression Results}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/regressor_comparison.png}
    \caption{Regression model comparison by R² score. Ensemble methods (Random Forest, Gradient Boosting) achieve near-perfect R² $>$ 0.99. Linear models achieve R² $\approx$ 0.85--0.90.}
    \label{fig:reg_compare}
\end{figure}

\begin{table}[H]
\centering
\caption{Regression Results Summary}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{R²} & \textbf{RMSE (MPG)} & \textbf{MAE (MPG)} \\
\midrule
\textbf{Random Forest} & \textbf{0.938} & 4.52 & 2.31 \\
Gradient Boosting & 0.932 & 4.70 & 2.58 \\
KNN (k=5) & 0.928 & 4.84 & 2.65 \\
SVR (RBF) & 0.915 & 5.26 & 2.77 \\
Ridge (L2) & 0.802 & 8.05 & 4.47 \\
Lasso (L1) & 0.800 & 8.08 & 4.48 \\
Huber (Robust) & 0.782 & 8.45 & 3.75 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Actual vs Predicted}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/figures/actual_vs_predicted.png}
    \caption{Actual vs Predicted MPG (Gradient Boosting). Points cluster tightly along the diagonal, indicating excellent predictions. Larger vehicles (lower MPG) and EVs (higher MPG) are both well-predicted.}
    \label{fig:actual_pred}
\end{figure}

\subsubsection{Feature Importance}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../results/figures/feature_importance_regression.png}
    \caption{Feature importance for fuel economy prediction. Vehicle class, engine displacement, fuel type, and cylinders dominate---all physically meaningful.}
    \label{fig:reg_imp}
\end{figure}

\subsubsection{Residual Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{../results/figures/residuals.png}
    \caption{Residual analysis. \textbf{Left}: Residuals vs predicted values show no systematic pattern (good). \textbf{Right}: Residual distribution is approximately normal with slight tails for extreme vehicles.}
    \label{fig:resid}
\end{figure}

\subsection{Regression Summary}

The regression task achieves strong predictions (R² = 0.94 for Random Forest) because fuel economy is strongly determined by vehicle specifications. Key findings:

\begin{itemize}[leftmargin=*]
    \item \textbf{Ensemble methods dominate}: Random Forest and Gradient Boosting capture non-linear relationships best
    \item \textbf{Feature importance aligns with physics}: City/highway MPG, engine size, fuel type matter most
    \item \textbf{Production-ready}: Low error (RMSE $\approx$ 4.5 MPG) suitable for fleet cost estimation
    \item \textbf{KNN competitive}: Instance-based learning provides interpretable predictions
\end{itemize}

%==============================================================================
\section{Production Considerations}
%==============================================================================

\subsection{Deployment Recommendations}

\begin{table}[H]
\centering
\caption{Production Model Selection}
\begin{tabular}{p{4.5cm}p{4cm}p{4cm}}
\toprule
\textbf{Task} & \textbf{Recommended Model} & \textbf{Rationale} \\
\midrule
Driver Classification (current data) & \textbf{Logistic (L1/SCAD)} & 87.5\% accuracy, interpretable, fast \\
Driver Classification (more data) & Random Forest & Scales with more data \\
Driver Classification (time-series) & CNN (PyTorch) & Raw sensor patterns \\
Fuel Economy Prediction & Gradient Boosting & Highest R², handles non-linearity \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Monitoring \& Retraining}

\begin{itemize}[leftmargin=*]
    \item \textbf{Classification}: Monitor per-driver accuracy; retrain when new driver types emerge
    \item \textbf{Regression}: Monitor residual drift; retrain for new vehicle technologies (EVs, hybrids)
    \item \textbf{Feature drift}: Track feature distributions over time; alert on significant shifts
    \item \textbf{Model versioning}: Use MLflow or similar for experiment tracking
\end{itemize}

\subsection{Inference Performance}

\begin{table}[H]
\centering
\caption{Inference Time Comparison}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Single Prediction} & \textbf{Batch (1000)} \\
\midrule
Logistic Regression & $<$0.1 ms & $<$1 ms \\
Random Forest & $\sim$1 ms & $\sim$10 ms \\
CNN (PyTorch) & $\sim$5 ms & $\sim$50 ms \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Conclusions}
%==============================================================================

\subsection{Key Achievements}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Raw sensor features}: Extracted 36 features directly from GPS/accelerometer, avoiding circular logic from pre-computed scores
    \item \textbf{Rigorous evaluation}: D6 held-out ensures models generalize to new customers
    \item \textbf{Comprehensive comparison}: 18 classification + 13 regression models
    \item \textbf{Advanced regularization}: Implemented MCP and SCAD for nearly unbiased sparse estimates
    \item \textbf{Production insights}: Feature importance, failure analysis, deployment recommendations
    \item \textbf{Clean code}: Modular \texttt{src/classification/} package with testable functions
\end{enumerate}

\subsection{Final Results}

\begin{table}[H]
\centering
\caption{Final Results Summary}
\begin{tabular}{lcc}
\toprule
\textbf{Task} & \textbf{Best Model} & \textbf{Performance} \\
\midrule
Driver Behavior Classification & \textbf{Logistic (L1/SCAD)} & \textbf{87.5\% accuracy} (D6 held out) \\
Fuel Economy Prediction & Random Forest & R² = 0.94, RMSE = 4.5 MPG \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Insight}: On small datasets with well-engineered features, \textcolor{successgreen}{\textbf{sparse linear models outperform complex ensembles}}. Logistic Regression with L1 or SCAD regularization provides the best balance of accuracy, interpretability, and deployment simplicity.

\subsection{Lessons Learned}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Feature engineering matters}: Good raw sensor features enable simple models
    \item \textbf{Avoid circular logic}: Pre-computed scores inflate accuracy artificially
    \item \textbf{Driver-level evaluation}: Essential for production-realistic estimates
    \item \textbf{Simple models win on small data}: Complexity causes overfitting
    \item \textbf{Interpretability has value}: Explainable predictions enable business action
\end{enumerate}

\subsection{Future Work}

\begin{itemize}[leftmargin=*]
    \item \textbf{More data}: Collect 100+ trips for better deep learning performance
    \item \textbf{Temporal models}: LSTM/Transformer on raw time-series (not aggregated)
    \item \textbf{Driver normalization}: Per-driver baseline adjustment for personalization
    \item \textbf{Real-time scoring}: Streaming inference pipeline for live monitoring
    \item \textbf{Multi-task learning}: Predict behavior + severity simultaneously
\end{itemize}

\subsection{Reproducibility}

All code is available in the project repository with clean, modular architecture:

\begin{itemize}[leftmargin=*]
    \item \texttt{notebooks/01\_project\_overview.ipynb}: Project introduction
    \item \texttt{notebooks/02\_classification.ipynb}: Complete classification pipeline (757 lines with explanations)
    \item \texttt{notebooks/04\_regression.ipynb}: Complete regression pipeline
    \item \texttt{src/classification/}: Modular classification code
    \begin{itemize}
        \item \texttt{\_\_init\_\_.py}: Clean API exports
        \item \texttt{data.py}: Data loading and feature extraction
        \item \texttt{sparse\_models.py}: MCP and SCAD implementations
        \item \texttt{visualization.py}: All plotting functions
    \end{itemize}
    \item \texttt{src/models/}: Model implementations (CNN, etc.)
    \item \texttt{results/figures/}: All figures used in this report
\end{itemize}

\vspace{1cm}
\hrule
\vspace{0.5cm}
\textbf{Thank you for considering my application to ABAX.}

\end{document}

