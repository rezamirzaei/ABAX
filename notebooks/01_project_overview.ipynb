{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ðŸš— ABAX Data Science Project: Overview & Introduction\n",
    "\n",
    "**Author:** Reza Mirzaeifard\n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project addresses two machine learning tasks for ABAX telematics:\n",
    "\n",
    "### Task 1: Driver Behavior Classification\n",
    "**Goal:** Predict driver behavior (NORMAL, DROWSY, AGGRESSIVE) from smartphone sensor data\n",
    "\n",
    "### Task 2: Fuel Economy Prediction\n",
    "**Goal:** Predict vehicle fuel efficiency (MPG) from vehicle specifications\n",
    "\n",
    "---\n",
    "\n",
    "## Repository Structure\n",
    "\n",
    "```\n",
    "ABAX/\n",
    "â”œâ”€â”€ notebooks/\n",
    "â”‚   â”œâ”€â”€ 01_project_overview.ipynb    â† This file (project introduction)\n",
    "â”‚   â”œâ”€â”€ 02_classification.ipynb      â† Complete classification pipeline\n",
    "â”‚   â”œâ”€â”€ 03_eda_regression.ipynb      â† Regression EDA\n",
    "â”‚   â”œâ”€â”€ 04_regression.ipynb          â† Complete regression pipeline\n",
    "â”‚   â””â”€â”€ UAH_Drive_Set.ipynb          â† Original dataset exploration\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â”œâ”€â”€ data/                        â† Data loading & splitting\n",
    "â”‚   â”œâ”€â”€ features/                    â† Feature engineering\n",
    "â”‚   â”œâ”€â”€ models/                      â† Model training & evaluation\n",
    "â”‚   â”œâ”€â”€ visualization/               â† Plotting utilities\n",
    "â”‚   â””â”€â”€ utils/                       â† Helper functions\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ UAH-DRIVESET-v1/            â† Raw driving data\n",
    "â”‚   â””â”€â”€ processed/                   â† Extracted features\n",
    "â”œâ”€â”€ results/\n",
    "â”‚   â””â”€â”€ figures/                     â† Generated plots\n",
    "â””â”€â”€ docs/\n",
    "    â””â”€â”€ ABAX_Technical_Report.pdf    â† Complete technical report\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Results Summary\n",
    "\n",
    "| Task | Best Model | Performance | Key Insight |\n",
    "|------|------------|-------------|-------------|\n",
    "| **Classification** | Logistic Regression | 75% accuracy | Simple models win on small data |\n",
    "| **Regression** | Gradient Boosting | RÂ² > 0.99 | Strong feature-target relationship |\n",
    "\n",
    "---\n",
    "\n",
    "## Datasets\n",
    "\n",
    "### UAH-DriveSet (Classification)\n",
    "\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| Source | University of AlcalÃ¡ |\n",
    "| Drivers | 6 (D1-D6) |\n",
    "| Trips | 40 total |\n",
    "| Behaviors | NORMAL, DROWSY, AGGRESSIVE |\n",
    "| Sensors | GPS (1Hz), Accelerometer (~50Hz) |\n",
    "\n",
    "### EPA Fuel Economy (Regression)\n",
    "\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| Source | EPA Official Data |\n",
    "| Vehicles | 5,000 (2015-2024) |\n",
    "| Target | Combined MPG |\n",
    "| Features | Year, cylinders, displacement, drive, class, fuel type |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Design Decisions\n",
    "\n",
    "### 1. Raw Features Only (No Pre-computed Scores)\n",
    "\n",
    "**Problem:** The UAH-DriveSet includes pre-computed scores like `score_braking` and behavioral ratios like `ratio_aggressive`. Using these creates **circular logic** because they're computed using similar heuristics as the behavior labels.\n",
    "\n",
    "**Solution:** We extract features directly from raw GPS and accelerometer data:\n",
    "- Speed statistics (mean, std, max, min)\n",
    "- Acceleration statistics (x, y, magnitude)\n",
    "- Jerk (smoothness indicator)\n",
    "- Event counts (brakes, turns, hard events)\n",
    "\n",
    "### 2. Driver-Level Split (D6 Held Out)\n",
    "\n",
    "**Problem:** Random splits allow the model to learn driver-specific patterns, inflating accuracy by ~20%.\n",
    "\n",
    "**Solution:** Driver D6 is completely held out for testing. The model never sees D6 during training, simulating deployment to a new customer.\n",
    "\n",
    "### 3. Multiple Model Comparison\n",
    "\n",
    "We compare 16 classification algorithms and 13 regression algorithms to find the best accuracy-interpretability tradeoff.\n",
    "\n",
    "---\n"
   ],
   "id": "a3ba731fe01b538"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:12:56.078456Z",
     "start_time": "2025-12-28T23:12:55.765494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick environment check\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"ðŸ“ Project Structure:\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "\n",
    "# Check key directories\n",
    "dirs_to_check = ['data', 'notebooks', 'src', 'results', 'docs']\n",
    "for d in dirs_to_check:\n",
    "    path = project_root / d\n",
    "    exists = \"âœ…\" if path.exists() else \"âŒ\"\n",
    "    print(f\"   {exists} {d}/\")\n"
   ],
   "id": "602f5c915db4fc9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Project Structure:\n",
      "   Project root: /Users/rezami/PycharmProjects/ABAX\n",
      "   âœ… data/\n",
      "   âœ… notebooks/\n",
      "   âœ… src/\n",
      "   âœ… results/\n",
      "   âœ… docs/\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:12:56.298714Z",
     "start_time": "2025-12-28T23:12:56.081405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check data files\n",
    "print(\"\\nðŸ“Š Data Files:\")\n",
    "data_files = [\n",
    "    'data/processed/uah_raw_features.csv',\n",
    "    'data/processed/epa_fuel_economy.csv',\n",
    "]\n",
    "for f in data_files:\n",
    "    path = project_root / f\n",
    "    if path.exists():\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"   âœ… {f}: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {f}: NOT FOUND\")\n"
   ],
   "id": "a8b53e416b1d2ddb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Data Files:\n",
      "   âœ… data/processed/uah_raw_features.csv: (40, 39)\n",
      "   âœ… data/processed/epa_fuel_economy.csv: (5000, 39)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:12:56.383986Z",
     "start_time": "2025-12-28T23:12:56.300528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check result figures\n",
    "print(\"\\nðŸŽ¨ Result Figures:\")\n",
    "figures = [\n",
    "    'class_distribution.png',\n",
    "    'classifier_comparison.png',\n",
    "    'confusion_matrix_classification.png',\n",
    "    'feature_importance_classification.png',\n",
    "    'cnn_learning_curves_classification.png',\n",
    "]\n",
    "for f in figures:\n",
    "    path = project_root / 'results' / 'figures' / f\n",
    "    exists = \"âœ…\" if path.exists() else \"âŒ\"\n",
    "    print(f\"   {exists} {f}\")\n"
   ],
   "id": "cb42a391e0dbfdd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¨ Result Figures:\n",
      "   âœ… class_distribution.png\n",
      "   âœ… classifier_comparison.png\n",
      "   âœ… confusion_matrix_classification.png\n",
      "   âœ… feature_importance_classification.png\n",
      "   âœ… cnn_learning_curves_classification.png\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## How to Use This Project\n",
    "\n",
    "### 1. Classification Pipeline\n",
    "Open `02_classification.ipynb` for the complete driver behavior classification:\n",
    "- Raw data exploration\n",
    "- Feature engineering\n",
    "- EDA with visualizations\n",
    "- Model training (16 algorithms)\n",
    "- CNN deep learning\n",
    "- Evaluation and analysis\n",
    "\n",
    "### 2. Regression Pipeline\n",
    "Open `04_regression.ipynb` for fuel economy prediction:\n",
    "- Data loading and preprocessing\n",
    "- Feature engineering\n",
    "- Model training (13 algorithms)\n",
    "- Evaluation with residual analysis\n",
    "\n",
    "### 3. Technical Report\n",
    "Read `docs/ABAX_Technical_Report.pdf` for:\n",
    "- Complete methodology\n",
    "- All results and figures\n",
    "- Failure analysis\n",
    "- Production recommendations\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "```python\n",
    "# Load the classification dataset\n",
    "import pandas as pd\n",
    "from src.data import split_by_driver\n",
    "\n",
    "df = pd.read_csv('data/processed/uah_raw_features.csv')\n",
    "X = df.drop(columns=['driver', 'behavior', 'road_type'])\n",
    "y = df['behavior']\n",
    "\n",
    "# Split with D6 held out\n",
    "X_train, X_test, y_train, y_test = split_by_driver(\n",
    "    df[list(X.columns) + ['driver']],\n",
    "    y.values,\n",
    "    test_drivers=['D6']\n",
    ")\n",
    "\n",
    "# Train best model (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "accuracy = model.score(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### Classification\n",
    "\n",
    "1. **Logistic Regression wins** on this small dataset (75% accuracy)\n",
    "2. **Raw sensor features** avoid circular logic from pre-computed scores\n",
    "3. **D6 held-out** provides realistic evaluation for new customers\n",
    "4. **Feature importance**: Speed variance, jerk, and event counts are most predictive\n",
    "\n",
    "### Regression\n",
    "\n",
    "1. **Ensemble methods dominate** (RÂ² > 0.99)\n",
    "2. **Vehicle class and fuel type** are most important features\n",
    "3. **Linear models also strong** (RÂ² ~ 0.85-0.90)\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps for Production\n",
    "\n",
    "1. **Collect more data**: 40 trips is too small for deep learning\n",
    "2. **Temporal models**: Try LSTM/Transformer on raw time-series\n",
    "3. **Real-time scoring**: Implement streaming inference\n",
    "4. **Driver normalization**: Adjust for individual driver baselines\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ“š Continue to `02_classification.ipynb` for the full classification pipeline â†’**\n"
   ],
   "id": "6fe835bf44bee7c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:12:56.407522Z",
     "start_time": "2025-12-28T23:12:56.386301Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "99166e3cf591e0f4",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
