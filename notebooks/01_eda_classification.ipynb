{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üöó Driver Behavior Classification - EDA\n",
    "\n",
    "**Author:** Reza Mirzaeifard  \n",
    "**Date:** December 2025  \n",
    "**Dataset:** UAH-DriveSet (Real-world driving telemetry)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: If imports fail\n",
    "\n",
    "**Restart the Jupyter Kernel first!**\n",
    "- In JupyterLab: `Kernel ‚Üí Restart Kernel`\n",
    "- In PyCharm: `Run ‚Üí Restart Kernel`\n"
   ],
   "id": "4a98f9071856db14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1: Clear all cached src modules\n",
    "import sys\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if mod.startswith('src'):\n",
    "        del sys.modules[mod]\n",
    "\n",
    "# Step 2: Add project root to path\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n"
   ],
   "id": "5014a413e1d4431f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3: Standard library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 4: Project imports\n",
    "from src.data import load_uah_driveset\n",
    "from src.features import (\n",
    "    analyze_class_distribution,\n",
    "    analyze_correlations,\n",
    "    analyze_outliers_dataframe,\n",
    "    generate_data_quality_report,\n",
    "    analyze_driver_distribution,\n",
    "    print_score_mapping_explanation,\n",
    "    print_outlier_summary,\n",
    ")\n",
    "from src.visualization import (\n",
    "    setup_style,\n",
    "    plot_class_distribution_from_result,\n",
    "    plot_driver_behavior_distribution,\n",
    "    plot_feature_by_target,\n",
    "    plot_outlier_summary,\n",
    "    plot_correlation_matrix,\n",
    ")\n",
    "from src.utils import (\n",
    "    print_dataset_info,\n",
    "    print_class_distribution_result,\n",
    "    print_success,\n",
    ")\n",
    "\n",
    "setup_style()\n",
    "print_success('All imports successful!')\n"
   ],
   "id": "e9e66fd88ce4ee18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### Problem Statement\n",
    "Predict driver behavior: **NORMAL / DROWSY / AGGRESSIVE**\n",
    "\n",
    "### Dataset: UAH-DriveSet\n",
    "- **Source**: University of Alcal√° (naturalistic driving data)\n",
    "- **Drivers**: 6 drivers (D1-D6)\n",
    "- **Behaviors**: 3 classes (Normal, Drowsy, Aggressive)\n",
    "- **Road types**: Motorway, Secondary\n",
    "- **Data**: ~40 trips with telemetry features\n",
    "\n",
    "### Key Innovation: Driver-Level Splitting\n",
    "**Why it matters**: Random splits leak information (same driver in train & test).  \n",
    "**Solution**: Hold out entire drivers (D6) for testing ‚Üí ensures generalization to NEW drivers.\n",
    "\n",
    "### Feature Engineering Philosophy\n",
    "\n",
    "**Q: Why aggregate trip-level features instead of time-series?**\n",
    "\n",
    "**A:**\n",
    "1. **Variable trip lengths**: Trips range from 13-26km with different durations\n",
    "2. **Real-world applicability**: Aggregate statistics work without fixed window lengths\n",
    "3. **Domain knowledge**: Ratios and scores (% aggressive maneuvers) are scale-invariant\n",
    "4. **Production-ready**: Easy to compute in real-time systems\n",
    "\n",
    "**Q: What about different window lengths in production?**\n",
    "\n",
    "**A:**\n",
    "- **Current approach**: Aggregate over entire trips (no fixed window needed)\n",
    "- **Alternative 1**: Rolling statistics over fixed windows (e.g., 5-min segments)\n",
    "- **Alternative 2**: RNN/Transformer on raw time-series with padding/truncation\n",
    "- **Our choice**: Practical, interpretable, and scalable for deployment\n",
    "\n",
    "---\n"
   ],
   "id": "4d66b1f10ed93a5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Understanding Score Mapping (Accelerometer ‚Üí Scores)\n",
    "\n",
    "The UAH-DriveSet uses the **DriveSafe iOS app** to compute behavioral scores from raw accelerometer data.\n"
   ],
   "id": "de64ebbff5d6834f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T07:47:54.329549Z",
     "start_time": "2025-12-26T07:47:54.303628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the score mapping explanation\n",
    "print(print_score_mapping_explanation())\n"
   ],
   "id": "fa8699a48b7b7ebf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UAH-DriveSet Score Mapping (from DriveSafe App)\n",
      "================================================\n",
      "\n",
      "The scores are computed by the DriveSafe iOS app from accelerometer data:\n",
      "\n",
      "1. **Raw Data Collection**:\n",
      "   - Accelerometer: 3-axis acceleration at ~50Hz\n",
      "   - GPS: Position, speed at ~1Hz\n",
      "\n",
      "2. **Event Detection** (from SEMANTIC_FINAL.txt):\n",
      "   - Low/Medium/High Accelerations (Lacc, Macc, Hacc)\n",
      "   - Low/Medium/High Brakings (Lbra, Mbra, Hbra)  \n",
      "   - Low/Medium/High Turnings (Ltur, Mtur, Htur)\n",
      "   \n",
      "   Events are classified by acceleration magnitude thresholds:\n",
      "   - Low: 0.2-0.5g\n",
      "   - Medium: 0.5-0.8g\n",
      "   - High: >0.8g\n",
      "\n",
      "3. **Score Computation** (0-100 scale):\n",
      "   - score_accelerations: Based on Lacc, Macc, Hacc counts\n",
      "   - score_brakings: Based on Lbra, Mbra, Hbra counts\n",
      "   - score_turnings: Based on Ltur, Mtur, Htur counts\n",
      "   - score_weaving: Lane discipline from lateral movement\n",
      "   - score_drifting: Lane keeping from GPS trajectory\n",
      "   - score_overspeeding: Speed compliance vs road limits\n",
      "   - score_following: Following distance estimation\n",
      "   - score_total: Mean of all 7 scores\n",
      "\n",
      "4. **Behavior Ratios** (0-1 scale):\n",
      "   - ratio_normal: Proportion of trip with normal driving\n",
      "   - ratio_drowsy: Proportion with drowsy indicators\n",
      "   - ratio_aggressive: Proportion with aggressive indicators\n",
      "\n",
      "   Computed using sliding 60-second windows.\n",
      "\n",
      "5. **Aggregation for Classification**:\n",
      "   We use the FINAL scores (last row of SEMANTIC_ONLINE.txt)\n",
      "   which represent the complete trip statistics.\n",
      "   This avoids fixed-window assumptions for variable trip lengths.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Load Data with Driver Information\n",
    "\n",
    "We preserve driver information for proper **driver-level splitting** later.\n"
   ],
   "id": "6988fe2c187f9951"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T07:47:54.887872Z",
     "start_time": "2025-12-26T07:47:54.334976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_uah_driveset(\n",
    "    data_dir=str(project_root / 'data' / 'UAH-DRIVESET-v1'),\n",
    "    task='classification',\n",
    "    return_driver_info=True\n",
    ")\n",
    "\n",
    "print_dataset_info(dataset.info)\n",
    "\n",
    "df = pd.DataFrame(dataset.X, columns=dataset.feature_names)\n",
    "df['behavior'] = dataset.y.values\n",
    "\n",
    "print(f\"\\nüîç Shape: {df.shape}\")\n",
    "print(f\"\\nüìã First 10 samples:\")\n",
    "df.head(10)\n"
   ],
   "id": "a250a6baeaf5735f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Dataset: UAH-DriveSet\n",
      "   Samples: 40\n",
      "   Features: 11\n",
      "   Task: classification\n",
      "\n",
      "üîç Shape: (40, 13)\n",
      "\n",
      "üìã First 10 samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   score_total  score_accelerations  score_brakings  score_turnings  \\\n",
       "0         90.0                100.0           100.0           100.0   \n",
       "1         80.4                100.0            49.1           100.0   \n",
       "2         70.7                100.0             0.0           100.0   \n",
       "3         89.4                100.0           100.0           100.0   \n",
       "4         62.7                100.0             0.0            59.7   \n",
       "5         84.5                100.0           100.0            53.7   \n",
       "6         87.8                100.0           100.0           100.0   \n",
       "7         67.2                100.0             0.0           100.0   \n",
       "8         87.5                 75.6            75.6           100.0   \n",
       "9         55.0                 73.1             5.5            49.4   \n",
       "\n",
       "   score_weaving  score_drifting  score_overspeeding  score_following  \\\n",
       "0          100.0            63.7                66.2            100.0   \n",
       "1          100.0            53.7                59.8            100.0   \n",
       "2          100.0            90.0                79.3             25.6   \n",
       "3          100.0            26.2               100.0             99.6   \n",
       "4          100.0            61.5                95.9             22.1   \n",
       "5          100.0            47.0                90.8            100.0   \n",
       "6           33.3            82.1               100.0             99.5   \n",
       "7          100.0            92.6                78.0              0.0   \n",
       "8          100.0            65.0               100.0             96.2   \n",
       "9          100.0            59.6                97.8              0.0   \n",
       "\n",
       "   ratio_normal  ratio_drowsy  ratio_aggressive driver    behavior  \n",
       "0         0.742         0.145             0.113     D1      NORMAL  \n",
       "1         0.480         0.278             0.242     D1      DROWSY  \n",
       "2         0.428         0.063             0.509     D1  AGGRESSIVE  \n",
       "3         0.464         0.443             0.093     D1      DROWSY  \n",
       "4         0.172         0.233             0.595     D1  AGGRESSIVE  \n",
       "5         0.652         0.212             0.136     D1      NORMAL  \n",
       "6         0.411         0.436             0.153     D1      NORMAL  \n",
       "7         0.287         0.047             0.666     D2  AGGRESSIVE  \n",
       "8         0.616         0.210             0.174     D2      DROWSY  \n",
       "9         0.003         0.243             0.755     D2  AGGRESSIVE  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_total</th>\n",
       "      <th>score_accelerations</th>\n",
       "      <th>score_brakings</th>\n",
       "      <th>score_turnings</th>\n",
       "      <th>score_weaving</th>\n",
       "      <th>score_drifting</th>\n",
       "      <th>score_overspeeding</th>\n",
       "      <th>score_following</th>\n",
       "      <th>ratio_normal</th>\n",
       "      <th>ratio_drowsy</th>\n",
       "      <th>ratio_aggressive</th>\n",
       "      <th>driver</th>\n",
       "      <th>behavior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>66.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.113</td>\n",
       "      <td>D1</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>53.7</td>\n",
       "      <td>59.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>D1</td>\n",
       "      <td>DROWSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>79.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.509</td>\n",
       "      <td>D1</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.093</td>\n",
       "      <td>D1</td>\n",
       "      <td>DROWSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>95.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.595</td>\n",
       "      <td>D1</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>53.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>90.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.136</td>\n",
       "      <td>D1</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>82.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.153</td>\n",
       "      <td>D1</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.6</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.666</td>\n",
       "      <td>D2</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>75.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.174</td>\n",
       "      <td>D2</td>\n",
       "      <td>DROWSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>49.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>97.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.755</td>\n",
       "      <td>D2</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Save Processed Data\n",
   "id": "5f843d06ff57d557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T07:47:55.181856Z",
     "start_time": "2025-12-26T07:47:55.022298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_dir = project_root / 'data' / 'processed'\n",
    "processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "save_path = processed_dir / 'uah_classification.csv'\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f'\\nüíæ Saved to: {save_path}')\n",
    "print(f'   Shape: {df.shape}')\n"
   ],
   "id": "dc25d5a9aba3a8f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved to: /Users/rezami/PycharmProjects/ABAX/data/processed/uah_classification.csv\n",
      "   Shape: (40, 13)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Data Quality Report\n",
    "\n",
    "Using our `generate_data_quality_report()` function for comprehensive analysis.\n"
   ],
   "id": "2c73141bbd7516ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T07:47:56.838518Z",
     "start_time": "2025-12-26T07:47:55.381582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quality_report = generate_data_quality_report(\n",
    "    df=df,\n",
    "    target_column='behavior',\n",
    "    task_type='classification'\n",
    ")\n",
    "\n",
    "print(quality_report.summary())\n"
   ],
   "id": "ace5cda21e076706",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m quality_report = \u001B[43mgenerate_data_quality_report\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_column\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mbehavior\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtask_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mclassification\u001B[39;49m\u001B[33;43m'\u001B[39;49m\n\u001B[32m      5\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(quality_report.summary())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/src/features/analysis.py:435\u001B[39m, in \u001B[36mgenerate_data_quality_report\u001B[39m\u001B[34m(df, target_column, task_type)\u001B[39m\n\u001B[32m    433\u001B[39m correlation_analysis = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    434\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(numerical_cols) >= \u001B[32m2\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m435\u001B[39m     correlation_analysis = \u001B[43manalyze_correlations\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    436\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnumerical_cols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_column\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget_column\u001B[49m\n\u001B[32m    437\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    439\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m DataQualityReport(\n\u001B[32m    440\u001B[39m     n_samples=\u001B[38;5;28mlen\u001B[39m(df),\n\u001B[32m    441\u001B[39m     n_features=\u001B[38;5;28mlen\u001B[39m(numerical_cols) + \u001B[38;5;28mlen\u001B[39m(categorical_cols),\n\u001B[32m   (...)\u001B[39m\u001B[32m    448\u001B[39m     correlation_analysis=correlation_analysis,\n\u001B[32m    449\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/src/features/analysis.py:273\u001B[39m, in \u001B[36manalyze_correlations\u001B[39m\u001B[34m(df, columns, target_column, threshold)\u001B[39m\n\u001B[32m    271\u001B[39m target_correlations = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    272\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m target_column \u001B[38;5;129;01mand\u001B[39;00m target_column \u001B[38;5;129;01min\u001B[39;00m df.columns:\n\u001B[32m--> \u001B[39m\u001B[32m273\u001B[39m     target_corrs = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcorrwith\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget_column\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    274\u001B[39m     target_correlations = {col: \u001B[38;5;28mround\u001B[39m(val, \u001B[32m4\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m col, val \u001B[38;5;129;01min\u001B[39;00m target_corrs.items()}\n\u001B[32m    276\u001B[39m multicollinearity_warning = \u001B[38;5;28many\u001B[39m(\u001B[38;5;28mabs\u001B[39m(c) > \u001B[32m0.9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _, _, c \u001B[38;5;129;01min\u001B[39;00m high_corr_pairs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10301\u001B[39m, in \u001B[36mDataFrame.corrwith\u001B[39m\u001B[34m(self, other, axis, drop, method, numeric_only)\u001B[39m\n\u001B[32m  10298\u001B[39m this = \u001B[38;5;28mself\u001B[39m._get_numeric_data() \u001B[38;5;28;01mif\u001B[39;00m numeric_only \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[32m  10300\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, Series):\n\u001B[32m> \u001B[39m\u001B[32m10301\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mthis\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m  10303\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m numeric_only:\n\u001B[32m  10304\u001B[39m     other = other._get_numeric_data()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001B[39m, in \u001B[36mDataFrame.apply\u001B[39m\u001B[34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[39m\n\u001B[32m   9412\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapply\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[32m   9414\u001B[39m op = frame_apply(\n\u001B[32m   9415\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   9416\u001B[39m     func=func,\n\u001B[32m   (...)\u001B[39m\u001B[32m   9421\u001B[39m     kwargs=kwargs,\n\u001B[32m   9422\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m9423\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m.__finalize__(\u001B[38;5;28mself\u001B[39m, method=\u001B[33m\"\u001B[39m\u001B[33mapply\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/apply.py:678\u001B[39m, in \u001B[36mFrameApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    675\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.raw:\n\u001B[32m    676\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_raw()\n\u001B[32m--> \u001B[39m\u001B[32m678\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/apply.py:798\u001B[39m, in \u001B[36mFrameApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    797\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m798\u001B[39m     results, res_index = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    800\u001B[39m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[32m    801\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.wrap_results(results, res_index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/apply.py:814\u001B[39m, in \u001B[36mFrameApply.apply_series_generator\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    811\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[33m\"\u001B[39m\u001B[33mmode.chained_assignment\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    812\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[32m    813\u001B[39m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m814\u001B[39m         results[i] = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    815\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[32m    816\u001B[39m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[32m    817\u001B[39m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[32m    818\u001B[39m             results[i] = results[i].copy(deep=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10301\u001B[39m, in \u001B[36mDataFrame.corrwith.<locals>.<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m  10298\u001B[39m this = \u001B[38;5;28mself\u001B[39m._get_numeric_data() \u001B[38;5;28;01mif\u001B[39;00m numeric_only \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[32m  10300\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, Series):\n\u001B[32m> \u001B[39m\u001B[32m10301\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m this.apply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mother\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m, axis=axis)\n\u001B[32m  10303\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m numeric_only:\n\u001B[32m  10304\u001B[39m     other = other._get_numeric_data()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/series.py:2727\u001B[39m, in \u001B[36mSeries.corr\u001B[39m\u001B[34m(self, other, method, min_periods)\u001B[39m\n\u001B[32m   2724\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.nan\n\u001B[32m   2726\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33mpearson\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mspearman\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mkendall\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(method):\n\u001B[32m-> \u001B[39m\u001B[32m2727\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnanops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnancorr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2728\u001B[39m \u001B[43m        \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_periods\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmin_periods\u001B[49m\n\u001B[32m   2729\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2731\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2732\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmethod must be either \u001B[39m\u001B[33m'\u001B[39m\u001B[33mpearson\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2733\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[33mspearman\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m\u001B[33mkendall\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, or a callable, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2734\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmethod\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m was supplied\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2735\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/nanops.py:96\u001B[39m, in \u001B[36mdisallow.__call__.<locals>._f\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     94\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m np.errstate(invalid=\u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     98\u001B[39m     \u001B[38;5;66;03m# we want to transform an object array\u001B[39;00m\n\u001B[32m     99\u001B[39m     \u001B[38;5;66;03m# ValueError message to the more typical TypeError\u001B[39;00m\n\u001B[32m    100\u001B[39m     \u001B[38;5;66;03m# e.g. this is normally a disallowed function on\u001B[39;00m\n\u001B[32m    101\u001B[39m     \u001B[38;5;66;03m# object arrays that contain strings\u001B[39;00m\n\u001B[32m    102\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_object_dtype(args[\u001B[32m0\u001B[39m]):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/nanops.py:1614\u001B[39m, in \u001B[36mnancorr\u001B[39m\u001B[34m(a, b, method, min_periods)\u001B[39m\n\u001B[32m   1611\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.nan\n\u001B[32m   1613\u001B[39m f = get_corr_func(method)\n\u001B[32m-> \u001B[39m\u001B[32m1614\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/pandas/core/nanops.py:1637\u001B[39m, in \u001B[36mget_corr_func.<locals>.func\u001B[39m\u001B[34m(a, b)\u001B[39m\n\u001B[32m   1636\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfunc\u001B[39m(a, b):\n\u001B[32m-> \u001B[39m\u001B[32m1637\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcorrcoef\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:2889\u001B[39m, in \u001B[36mcorrcoef\u001B[39m\u001B[34m(x, y, rowvar, bias, ddof, dtype)\u001B[39m\n\u001B[32m   2885\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np._NoValue \u001B[38;5;129;01mor\u001B[39;00m ddof \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np._NoValue:\n\u001B[32m   2886\u001B[39m     \u001B[38;5;66;03m# 2015-03-15, 1.10\u001B[39;00m\n\u001B[32m   2887\u001B[39m     warnings.warn(\u001B[33m'\u001B[39m\u001B[33mbias and ddof have no effect and are deprecated\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   2888\u001B[39m                   \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2889\u001B[39m c = \u001B[43mcov\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrowvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2890\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2891\u001B[39m     d = diag(c)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:2724\u001B[39m, in \u001B[36mcov\u001B[39m\u001B[34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001B[39m\n\u001B[32m   2721\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2722\u001B[39m         w *= aweights\n\u001B[32m-> \u001B[39m\u001B[32m2724\u001B[39m avg, w_sum = \u001B[43maverage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m=\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturned\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   2725\u001B[39m w_sum = w_sum[\u001B[32m0\u001B[39m]\n\u001B[32m   2727\u001B[39m \u001B[38;5;66;03m# Determine the normalization\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:520\u001B[39m, in \u001B[36maverage\u001B[39m\u001B[34m(a, axis, weights, returned, keepdims)\u001B[39m\n\u001B[32m    517\u001B[39m     keepdims_kw = {\u001B[33m'\u001B[39m\u001B[33mkeepdims\u001B[39m\u001B[33m'\u001B[39m: keepdims}\n\u001B[32m    519\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m520\u001B[39m     avg = \u001B[43ma\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkeepdims_kw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    521\u001B[39m     avg_as_array = np.asanyarray(avg)\n\u001B[32m    522\u001B[39m     scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/ABAX/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:121\u001B[39m, in \u001B[36m_mean\u001B[39m\u001B[34m(a, axis, dtype, out, keepdims, where)\u001B[39m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, mu.ndarray):\n\u001B[32m    120\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m _no_nep50_warning():\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m         ret = \u001B[43mum\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrue_divide\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m                \u001B[49m\u001B[43mret\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrcount\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mret\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43munsafe\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubok\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    123\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_float16_result \u001B[38;5;129;01mand\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    124\u001B[39m         ret = arr.dtype.type(ret)\n",
      "\u001B[31mTypeError\u001B[39m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Class Distribution\n",
    "\n",
    "Using our `analyze_class_distribution()` function.\n"
   ],
   "id": "bf509f5468d1daa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_result = analyze_class_distribution(df['behavior'])\n",
    "\n",
    "print_class_distribution_result(class_result)\n",
    "\n",
    "# Plot using our visualization function\n",
    "fig = plot_class_distribution_from_result(class_result, title='Driver Behavior Distribution')\n",
    "plt.savefig(project_root / 'results' / 'figures' / 'class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "367bd5f7fb2cd79d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Driver Distribution\n",
    "\n",
    "Using our `analyze_driver_distribution()` function.\n"
   ],
   "id": "4aedbdaf1e259b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "driver_crosstab = analyze_driver_distribution(df, driver_column='driver', behavior_column='behavior')\n",
    "\n",
    "print(\"\\nüë• Trips per driver:\")\n",
    "driver_counts = df['driver'].value_counts().sort_index()\n",
    "for driver, count in driver_counts.items():\n",
    "    print(f\"   {driver}: {count} trips\")\n",
    "\n",
    "print(\"\\nüîÑ Driver √ó Behavior:\")\n",
    "print(driver_crosstab)\n",
    "\n",
    "# Plot using our visualization function\n",
    "fig = plot_driver_behavior_distribution(driver_crosstab)\n",
    "plt.savefig(project_root / 'results' / 'figures' / 'driver_behavior_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Strategy: Hold out D6 for testing (driver-level split)\")\n",
    "print(\"   This ensures generalization to NEW DRIVERS\")\n"
   ],
   "id": "d053f7bf283409bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Feature Overview\n",
   "id": "abeb5a9a5b478518"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_cols = [c for c in df.columns if c not in ['behavior', 'driver']]\n",
    "\n",
    "print(f\"\\nüìã Features ({len(feature_cols)}):\")\n",
    "for i, feat in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "\n",
    "print(\"\\nüìä Feature Statistics:\")\n",
    "df[feature_cols].describe().T\n"
   ],
   "id": "a5d3381828a864cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Outlier Analysis\n",
    "\n",
    "Using our `analyze_outliers_dataframe()` function.\n"
   ],
   "id": "19bab968b75bcbeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "outlier_results = analyze_outliers_dataframe(df, columns=feature_cols)\n",
    "\n",
    "print(\"\\nüîç Outlier Analysis (IQR method):\")\n",
    "for result in outlier_results:\n",
    "    status = \"‚ö†Ô∏è\" if result.has_significant_outliers else \"‚úÖ\"\n",
    "    print(f\"   {status} {result.column}: {result.n_outliers} outliers ({result.outlier_percentage:.1f}%)\")\n",
    "\n",
    "# Plot outlier summary\n",
    "fig = plot_outlier_summary(outlier_results, title='Outlier Analysis by Feature')\n",
    "plt.savefig(project_root / 'results' / 'figures' / 'outlier_analysis_classification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "b41cfcf1358069f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Feature Distributions by Behavior\n",
    "\n",
    "Using our `plot_feature_by_target()` function.\n"
   ],
   "id": "b55dee18744aef02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "key_features = ['score_total', 'score_accelerations', 'score_brakings',\n",
    "                'score_overspeeding', 'score_weaving', 'score_drifting']\n",
    "key_features = [f for f in key_features if f in df.columns]\n",
    "\n",
    "fig = plot_feature_by_target(df, feature_columns=key_features, target_column='behavior', n_cols=3)\n",
    "plt.savefig(project_root / 'results' / 'figures' / 'feature_distributions_classification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Clear separation indicates good classification potential\")\n"
   ],
   "id": "e1baeb3d3f8e5a64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 11. Correlation Analysis\n",
    "\n",
    "Using our `analyze_correlations()` function.\n"
   ],
   "id": "a5c5839f287f9fb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_result = analyze_correlations(df, columns=feature_cols, threshold=0.8)\n",
    "\n",
    "# Plot correlation matrix\n",
    "fig = plot_correlation_matrix(df, columns=feature_cols)\n",
    "plt.savefig(project_root / 'results' / 'figures' / 'correlation_matrix_classification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "if corr_result.high_correlation_pairs:\n",
    "    print(\"\\n‚ö†Ô∏è Highly correlated features (|r| > 0.8):\")\n",
    "    for f1, f2, corr in corr_result.high_correlation_pairs:\n",
    "        print(f\"   {f1} ‚Üî {f2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No highly correlated features\")\n",
    "\n",
    "if corr_result.multicollinearity_warning:\n",
    "    print(\"\\n‚ö†Ô∏è Multicollinearity detected - consider Ridge regularization\")\n"
   ],
   "id": "6bce771d1af8e806",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 12. Key Takeaways\n",
    "\n",
    "### ‚úÖ Data Quality\n",
    "- Real-world telemetry (not synthetic)\n",
    "- Balanced classes (from quality report)\n",
    "- Multiple drivers for generalization testing\n",
    "- Variable trip lengths handled via aggregation\n",
    "\n",
    "### üéØ Feature Engineering Success\n",
    "- **Aggregate statistics**: Robust to variable trip lengths\n",
    "- **Domain-driven**: Score-based features from telematics research\n",
    "- **Production-ready**: Easy to compute in real-time\n",
    "- **Interpretable**: Clear meaning for domain experts\n",
    "\n",
    "### üìä Modeling Strategy\n",
    "1. **Driver-level split**: Hold out D6 to test generalization\n",
    "2. **Model comparison**: Logistic Regression, Random Forest, CNN\n",
    "3. **Evaluation**: F1-score, confusion matrix, learning curves\n",
    "4. **Business relevance**: Fleet safety, insurance risk, driver coaching\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ EDA complete ‚Üí Ready for modeling in `02_classification.ipynb`**\n"
   ],
   "id": "b4152c68e3b91f2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
